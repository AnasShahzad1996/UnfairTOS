{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0747e321",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------# Import libraries and datasets #------#\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer\n",
    "import datasets as dts\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import re\n",
    "import gc\n",
    "%matplotlib inline\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from transformers import BertModel\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1bdd8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset lex_glue (/home/anas/.cache/huggingface/datasets/lex_glue/unfair_tos/1.0.0/8a66420941bf6e77a7ddd4da4d3bfb7ba88ef48c1d55302a568ac650a095ca3a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdb9437d2e0144ba89f3e3475b2f1218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dts.load_dataset('lex_glue','unfair_tos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "938c7242",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.DataFrame.from_dict(dataset[\"train\"])\n",
    "val_dataset = pd.DataFrame.from_dict(dataset[\"validation\"])\n",
    "test_dataset = pd.DataFrame.from_dict(dataset[\"test\"])\n",
    "\n",
    "stop_words = list(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6004daaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "definitions = {\"Limitation of liability\": [\"This clause stipulates that the duty to pay damages is limited or excluded, for certain kind of losses, under certain conditions. \"]\n",
    "               , \"Unilateral termination\": [\"This clause gives provider the right to suspend and/or terminate the service and/or the contract, and sometimes details the circumstances under which the provider claims to have a right to do so.\"]\n",
    "               , \"Unilateral change\": [\"This clause specifies the conditions under which the service provider could amend and modify the terms of service and/or the service itself.\"]\n",
    "               , \"Content removal\": [\"This clause gives the provider a right to modify/delete userâ€™s content, including in-app purchases, and sometimes specifies the conditions under which the service provider may do so.\"]\n",
    "               , \"Contract by using\": [\"This clause stipulates that the consumer is bound by the terms of use of a specific service, simply by using the service, without even being required to mark that he or she has read and accepted them.\"]\n",
    "               , \"Choice of law\": [\"This clause specifies what law will govern the contract, meaning also what law will be applied in potential adjudication of a dispute arising under the contract.\"]\n",
    "               , \"Jurisdiction\": [\"This selection clause requires or allows the parties to resolve their disputes through an arbitration process, before the case could go to court.\"]\n",
    "               , \"Arbitration\": [\"This forum selection clause requires or allows the parties to resolve their disputes through an arbitration process, before the case could go to court however, such a clause may or may not specify that arbitration should occur within a specific jurisdiction. \"]}\n",
    "\n",
    "entailment_con = [\"entails\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588159dd",
   "metadata": {},
   "source": [
    "### Default with 8 + 1 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fd4e005f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTClassifier(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (fc): Linear(in_features=768, out_features=8, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc = nn.Linear(768, 8)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        _ , pooled_output = self.bert(input_ids=input_ids, attention_mask =attention_mask,return_dict=False)\n",
    "        #pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.fc(pooled_output)\n",
    "        return logits\n",
    "\n",
    "learning_rate = 1e-5\n",
    "num_classes = 8\n",
    "base_model = BERTClassifier(num_classes)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(base_model.parameters(), lr=learning_rate)\n",
    "print (base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "698e897f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataset,num_classes,tokenizer):\n",
    "        \n",
    "        self.dataset = dataset\n",
    "        self.texts = self.dataset[\"text\"]\n",
    "        self.labels = self.dataset[\"labels\"]\n",
    "        self.num_classes = num_classes\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text = self.texts[index]\n",
    "        label = self.labels[index]\n",
    "        \n",
    "        # Tokenize the text\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=64,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        input_ids = inputs['input_ids'].squeeze()\n",
    "        attention_mask = inputs['attention_mask'].squeeze()\n",
    "        #print (\"original label: \",label)\n",
    "        # Convert label to one-hot encoding\n",
    "        multi_label = torch.zeros(self.num_classes, dtype=torch.float32)\n",
    "        multi_label[label] = 1\n",
    "        #print (\"one hot multi : \",multi_label)\n",
    "        return {'input_ids':input_ids, 'attention_mask':attention_mask, 'multi_label':multi_label}\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "batch_size = 32\n",
    "train_custom = CustomDataset(train_dataset, num_classes,tokenizer)\n",
    "train_dataloader = DataLoader(train_custom, batch_size=batch_size, shuffle=True)\n",
    "#valid_custom = CustomDataset(val_dataset, num_classes,tokenizer)\n",
    "#val_dataloader = DataLoader(valid_custom, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "63e68bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overfitting on one example:\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "base_model.to(device)\n",
    "one_example = next(iter(dataloader))    \n",
    "\n",
    "def overfit_one(base_model,fit_example):\n",
    "    num_epochs = 100:\n",
    "    running_loss = []\n",
    "    for epoch in range(num_epochs):\n",
    "        base_model.train()  # Set the model to training mode            \n",
    "\n",
    "        input_ids = fit_example['input_ids'].to(device)\n",
    "        attention_mask = fit_example['attention_mask'].to(device)\n",
    "        targets = fit_example['multi_label'].to(device)\n",
    "\n",
    "\n",
    "        outputs = base_model(input_ids,attention_mask)\n",
    "        loss = loss_function(outputs.to(device), targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #print (iteration)\n",
    "        running_loss.append(loss.item())\n",
    "        if len(running_loss) > 20:\n",
    "            running_loss.pop(0)\n",
    "        print (f\"Epoch : {epoch} ,Iteration : {iteration}, training loss: {loss:.4f} , running loss:{sum(running_loss)/len(running_loss)}\",find_metrics(targets,outputs))\n",
    "\n",
    "        # freeing up excess memory\n",
    "        del loss, outputs\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d35c015f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 ,Iteration : 0, training loss: 0.0737 , running loss:0.0737270712852478 (0.59765625, 0.125, 0.0)\n",
      "Epoch : 0 ,Iteration : 1, training loss: 0.3944 , running loss:0.2340606153011322 (0.5859375, 0.20806451612903226, 0.0)\n",
      "Epoch : 0 ,Iteration : 2, training loss: 0.3834 , running loss:0.2838270664215088 (0.51953125, 0.191017316017316, 0.0)\n",
      "Epoch : 0 ,Iteration : 3, training loss: 0.2444 , running loss:0.2739791050553322 (0.46484375, 0.034722222222222224, 0.0)\n",
      "Epoch : 0 ,Iteration : 4, training loss: 0.3722 , running loss:0.29361444115638735 (0.453125, 0.059375000000000004, 0.0)\n",
      "Epoch : 0 ,Iteration : 5, training loss: 0.4274 , running loss:0.3159133394559224 (0.4609375, 0.06567887931034483, 0.0)\n",
      "Epoch : 0 ,Iteration : 6, training loss: 0.2001 , running loss:0.29936590577874866 (0.4453125, 0.03333333333333333, 0.0)\n",
      "Epoch : 0 ,Iteration : 7, training loss: 0.3787 , running loss:0.3092879597097635 (0.4609375, 0.023973607038123165, 0.0)\n",
      "Epoch : 0 ,Iteration : 8, training loss: 0.1462 , running loss:0.2911689496702618 (0.46875, 0.01785714285714286, 0.0)\n",
      "Epoch : 0 ,Iteration : 9, training loss: 0.5265 , running loss:0.31470475941896436 (0.4296875, 0.036121909888357256, 0.0)\n",
      "Epoch : 0 ,Iteration : 10, training loss: 0.1753 , running loss:0.3020297424359755 (0.42578125, 0.13970588235294118, 0.0)\n",
      "Epoch : 0 ,Iteration : 11, training loss: 0.3215 , running loss:0.30365301420291263 (0.48828125, 0.16647225422427037, 0.0)\n",
      "Epoch : 0 ,Iteration : 12, training loss: -0.0000 , running loss:0.2802950900334578 (0.43359375, 0.0, 0.0)\n",
      "Epoch : 0 ,Iteration : 13, training loss: 0.2163 , running loss:0.2757249559674944 (0.46875, 0.0331002331002331, 0.0)\n",
      "Epoch : 0 ,Iteration : 14, training loss: 0.1334 , running loss:0.2662352641423543 (0.41796875, 0.007575757575757576, 0.0)\n",
      "Epoch : 0 ,Iteration : 15, training loss: 0.4168 , running loss:0.27564413473010063 (0.453125, 0.05921994671994672, 0.0)\n",
      "Epoch : 0 ,Iteration : 16, training loss: 0.0682 , running loss:0.2634443610030062 (0.421875, 0.011904761904761904, 0.0)\n",
      "Epoch : 0 ,Iteration : 17, training loss: 0.2222 , running loss:0.2611504548953639 (0.453125, 0.03956228956228956, 0.0)\n",
      "Epoch : 0 ,Iteration : 18, training loss: 0.3464 , running loss:0.2656366091809775 (0.4140625, 0.01844532279314888, 0.0)\n",
      "Epoch : 0 ,Iteration : 19, training loss: 0.1632 , running loss:0.2605153266340494 (0.47265625, 0.03785714285714286, 0.0)\n",
      "Epoch : 0 ,Iteration : 20, training loss: 0.4071 , running loss:0.27718345560133456 (0.44140625, 0.054558823529411764, 0.0)\n",
      "Epoch : 0 ,Iteration : 21, training loss: 0.2360 , running loss:0.2692624006420374 (0.4765625, 0.04021417179311916, 0.0)\n",
      "Epoch : 0 ,Iteration : 22, training loss: 0.3297 , running loss:0.2665774870663881 (0.4921875, 0.05047619047619048, 0.0)\n",
      "Epoch : 0 ,Iteration : 23, training loss: 0.3043 , running loss:0.26957223005592823 (0.51171875, 0.05993357487922705, 0.0)\n",
      "Epoch : 0 ,Iteration : 24, training loss: 0.1658 , running loss:0.2592527810484171 (0.5078125, 0.02933264652014652, 0.0)\n",
      "Epoch : 0 ,Iteration : 25, training loss: 0.1831 , running loss:0.24703831113874913 (0.4765625, 0.14344532279314887, 0.0)\n",
      "Epoch : 0 ,Iteration : 26, training loss: 0.3780 , running loss:0.2559358265250921 (0.44921875, 0.17045454545454547, 0.0)\n",
      "Epoch : 0 ,Iteration : 27, training loss: 0.2559 , running loss:0.24979219250380993 (0.48046875, 0.02419354838709677, 0.0)\n",
      "Epoch : 0 ,Iteration : 28, training loss: 0.2504 , running loss:0.2550034295767546 (0.48046875, 0.031947261663286, 0.0)\n",
      "Epoch : 0 ,Iteration : 29, training loss: 0.2495 , running loss:0.24115410931408404 (0.48046875, 0.05063131313131313, 0.0)\n",
      "Epoch : 0 ,Iteration : 30, training loss: 0.2494 , running loss:0.24486039020121098 (0.5, 0.1921612394957983, 0.0)\n",
      "Epoch : 0 ,Iteration : 31, training loss: 0.3063 , running loss:0.244098636880517 (0.48828125, 0.171875, 0.0)\n",
      "Epoch : 0 ,Iteration : 32, training loss: 0.2082 , running loss:0.25450928695499897 (0.4765625, 0.008620689655172412, 0.0)\n",
      "Epoch : 0 ,Iteration : 33, training loss: 0.1870 , running loss:0.2530417490750551 (0.46875, 0.015909090909090907, 0.0)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18960/820326254.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m \u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_18960/820326254.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(base_model, train_dataloader, optimizer, loss_function)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;31m#print (iteration)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/legal_env/lib/python3.9/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/legal_env/lib/python3.9/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/legal_env/lib/python3.9/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             adam(params_with_grad,\n\u001b[0m\u001b[1;32m    235\u001b[0m                  \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                  \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/legal_env/lib/python3.9/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    301\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/legal_env/lib/python3.9/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "base_model.to(device)\n",
    "\n",
    "def find_metrics(targets,prediction):\n",
    "    final_pred = (torch.sigmoid(prediction) > 0.5) * 1.0\n",
    "    np_tar = targets.cpu().detach().numpy()\n",
    "    np_pred = final_pred.cpu().detach().numpy()\n",
    "    \n",
    "    avg_f1_mic = f1_score(np_tar.flatten(), np_pred.flatten(), average='micro',zero_division=1)\n",
    "    avg_f1_mac = f1_score(np_tar, np_pred, average='macro',zero_division=1)\n",
    "    avg_acc = accuracy_score(np_tar, np_pred)\n",
    "    del np_tar\n",
    "    del np_pred\n",
    "    del final_pred\n",
    "    return avg_f1_mic, avg_f1_mac, avg_acc\n",
    "\n",
    "    \n",
    "\n",
    "def train(base_model,train_dataloader,optimizer,loss_function):\n",
    "    # Training loop\n",
    "    num_epochs = 20\n",
    "    valid_interval = 10  # Perform validation and save model every 10 iterations\n",
    "    iteration = 0\n",
    "    \n",
    "    stop_criterion = 2000000\n",
    "\n",
    "    running_loss = []\n",
    "    for epoch in range(num_epochs):\n",
    "        base_model.train()  # Set the model to training mode\n",
    "        for curr_batch in train_dataloader:\n",
    "            \n",
    "            if iteration > stop_criterion:\n",
    "                break\n",
    "            \n",
    "            input_ids = curr_batch['input_ids'].to(device)\n",
    "            attention_mask = curr_batch['attention_mask'].to(device)\n",
    "            targets = curr_batch['multi_label'].to(device)\n",
    "\n",
    "\n",
    "            outputs = base_model(input_ids,attention_mask)\n",
    "            loss = loss_function(outputs.to(device), targets)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            #print (iteration)\n",
    "            running_loss.append(loss.item())\n",
    "            if len(running_loss) > 20:\n",
    "                running_loss.pop(0)\n",
    "            #print (f\"Epoch : {epoch} ,Iteration : {iteration}, training loss: {loss:.4f} , running loss:{sum(running_loss)/len(running_loss)}\")            \n",
    "            print (f\"Epoch : {epoch} ,Iteration : {iteration}, training loss: {loss:.4f} , running loss:{sum(running_loss)/len(running_loss)}\",find_metrics(targets,outputs))\n",
    "            \n",
    "            # freeing up excess memory\n",
    "            del loss, outputs\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            # Validation and model saving\n",
    "            '''if iteration % valid_interval == 0:\n",
    "                base_model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    total_loss = []\n",
    "                    f1_micro = []\n",
    "                    f1_macro = []\n",
    "                    f1_avg = []\n",
    "                    for val_batch in val_dataloader:\n",
    "                        val_input_ids = val_batch['input_ids'].to(device)\n",
    "                        val_attention_mask = val_batch['attention_mask'].to(device)\n",
    "                        val_targets = val_batch['multi_label'].to(device)\n",
    "\n",
    "\n",
    "                        outputs = base_model(val_input_ids,val_attention_mask)\n",
    "                        loss = loss_function(outputs.to(device), val_targets)                        \n",
    "                        \n",
    "                        total_loss.append(loss.item())\n",
    "                        val_out = find_metrics(val_targets,outputs)\n",
    "                        f1_micro.append(val_out[0])\n",
    "                        f1_macro.append(val_out[1])\n",
    "                        f1_avg.append(val_out[2])\n",
    "                        \n",
    "                        # emptying memory\n",
    "                        del val_out, loss, outputs\n",
    "                        gc.collect()\n",
    "                        torch.cuda.empty_cache()\n",
    "                        \n",
    "                    avg_acc = sum(f1_avg)/len(f1_avg)\n",
    "                    avg_f1mic = sum(f1_micro)/len(f1_micro)\n",
    "                    avg_f1mac = sum(f1_macro)/len(f1_macro)\n",
    "                    avg_loss = sum(total_loss)/len(total_loss)\n",
    "                    print (f\"Validation loss : {sum(total_loss)/len(total_loss)} \", ' ,acc : ',avg_loss,\" ,f1-micro : \",avg_f1mic,\" ,f1-macro : \",avg_f1mac)\n",
    "                    torch.save(base_model.state_dict(),f\"model_trained/model_{iteration}.pth\")\n",
    "                    #wandb.log({\"Validation Loss\": sum(total_loss)/len(total_loss)})\n",
    "                    del total_loss, f1_micro, f1_macro, f1_avg '''\n",
    "\n",
    "                #base_model.train()  # Set the model back to training mode\n",
    "            \n",
    "            iteration += 1\n",
    "    return base_model, train_dataloader, optimizer, loss_function\n",
    "\n",
    "base_model, train_dataloader, optimizer, loss_function = train(base_model,train_dataloader,optimizer,loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a758e8a",
   "metadata": {},
   "source": [
    "### Entailment training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8ead40ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7efb7a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337545\n",
      "<class 'torch.Tensor'> torch.Size([0])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([30522, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([2, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([8])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([8, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([1, 512])\n",
      "<class 'torch.Tensor'> torch.Size([1, 512])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([1, 64])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 12, 64, 64])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 12, 64])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 12, 64, 64])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 12, 64])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 12, 64, 64])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 12, 64])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 12, 64, 64])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 12, 64])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 12, 64, 64])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 12, 64])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 12, 64, 64])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 12, 64])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 12, 64, 64])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 12, 64])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 12, 64, 64])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 12, 64])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64])\n",
      "<class 'torch.Tensor'> torch.Size([64, 8])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64])\n",
      "<class 'torch.Tensor'> torch.Size([64, 8])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64])\n",
      "<class 'torch.Tensor'> torch.Size([1, 64])\n",
      "<class 'torch.Tensor'> torch.Size([64, 1, 1, 64])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 768])\n",
      "<class 'torch.Tensor'> torch.Size([64, 12, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "# prints currently alive Tensors and Variables\n",
    "import torch\n",
    "import gc\n",
    "print (len(gc.get_objects()))\n",
    "for obj in gc.get_objects():\n",
    "    try:\n",
    "        if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
    "            print(type(obj), obj.size())\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff64a326",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_54626/711957551.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "del val_dataset\n",
    "del test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99e95409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local variables:\n",
      "__name__: 57 bytes\n",
      "__doc__: 113 bytes\n",
      "__package__: 16 bytes\n",
      "__loader__: 16 bytes\n",
      "__spec__: 16 bytes\n",
      "__builtin__: 72 bytes\n",
      "__builtins__: 72 bytes\n",
      "_ih: 312 bytes\n",
      "_oh: 232 bytes\n",
      "_dh: 64 bytes\n",
      "In: 312 bytes\n",
      "Out: 232 bytes\n",
      "get_ipython: 64 bytes\n",
      "exit: 48 bytes\n",
      "quit: 48 bytes\n",
      "_: 49 bytes\n",
      "__: 49 bytes\n",
      "___: 49 bytes\n",
      "_i: 385 bytes\n",
      "_ii: 341 bytes\n",
      "_iii: 99 bytes\n",
      "_i1: 1634 bytes\n",
      "np: 72 bytes\n",
      "torch: 72 bytes\n",
      "nn: 72 bytes\n",
      "optim: 72 bytes\n",
      "Dataset: 1064 bytes\n",
      "DataLoader: 1472 bytes\n",
      "BertTokenizer: 2008 bytes\n",
      "dts: 72 bytes\n",
      "pd: 72 bytes\n",
      "sns: 72 bytes\n",
      "plt: 72 bytes\n",
      "nltk: 72 bytes\n",
      "re: 72 bytes\n",
      "gc: 72 bytes\n",
      "stopwords: 48 bytes\n",
      "CountVectorizer: 1064 bytes\n",
      "TfidfVectorizer: 1064 bytes\n",
      "WordCloud: 1064 bytes\n",
      "STOPWORDS: 8408 bytes\n",
      "SnowballStemmer: 1064 bytes\n",
      "train_test_split: 136 bytes\n",
      "TfidfTransformer: 1064 bytes\n",
      "MultinomialNB: 1064 bytes\n",
      "OneVsRestClassifier: 1064 bytes\n",
      "LinearSVC: 1064 bytes\n",
      "LogisticRegression: 1064 bytes\n",
      "Pipeline: 1064 bytes\n",
      "MultiLabelBinarizer: 1064 bytes\n",
      "BinaryRelevance: 1064 bytes\n",
      "ClassifierChain: 1064 bytes\n",
      "TomekLinks: 1064 bytes\n",
      "RandomUnderSampler: 1064 bytes\n",
      "BertModel: 1472 bytes\n",
      "f1_score: 136 bytes\n",
      "hamming_loss: 136 bytes\n",
      "accuracy_score: 136 bytes\n",
      "_i2: 100 bytes\n",
      "dataset: 248 bytes\n",
      "_i3: 267 bytes\n",
      "train_dataset: 1606340 bytes\n",
      "val_dataset: 681180 bytes\n",
      "test_dataset: 474769 bytes\n",
      "stop_words: 1488 bytes\n",
      "_i4: 5411 bytes\n",
      "definitions: 360 bytes\n",
      "entailment_con: 64 bytes\n",
      "_i5: 805 bytes\n",
      "BERTClassifier: 1472 bytes\n",
      "learning_rate: 24 bytes\n",
      "num_classes: 28 bytes\n",
      "base_model: 48 bytes\n",
      "loss_function: 48 bytes\n",
      "optimizer: 48 bytes\n",
      "_i6: 1494 bytes\n",
      "CustomDataset: 1064 bytes\n",
      "tokenizer: 48 bytes\n",
      "batch_size: 28 bytes\n",
      "train_custom: 48 bytes\n",
      "train_dataloader: 48 bytes\n",
      "valid_custom: 48 bytes\n",
      "valid_dataloader: 48 bytes\n",
      "_i7: 1872 bytes\n",
      "device: 24 bytes\n",
      "train: 136 bytes\n",
      "_i8: 99 bytes\n",
      "_i9: 783 bytes\n",
      "_i10: 1494 bytes\n",
      "_i11: 1872 bytes\n",
      "_i12: 1516 bytes\n",
      "_i13: 1872 bytes\n",
      "_i14: 765 bytes\n",
      "_i15: 1516 bytes\n",
      "_i16: 1872 bytes\n",
      "_i17: 1494 bytes\n",
      "_i18: 1872 bytes\n",
      "_i19: 341 bytes\n",
      "obj: 232 bytes\n",
      "_i20: 1876 bytes\n",
      "_i21: 99 bytes\n",
      "_i22: 341 bytes\n",
      "_i23: 385 bytes\n",
      "sys: 72 bytes\n",
      "name: 52 bytes\n",
      "value: 52 bytes\n",
      "_i24: 385 bytes\n",
      "Global variables:\n",
      "__name__: 57 bytes\n",
      "__doc__: 113 bytes\n",
      "__package__: 16 bytes\n",
      "__loader__: 16 bytes\n",
      "__spec__: 16 bytes\n",
      "__builtin__: 72 bytes\n",
      "__builtins__: 72 bytes\n",
      "_ih: 312 bytes\n",
      "_oh: 232 bytes\n",
      "_dh: 64 bytes\n",
      "In: 312 bytes\n",
      "Out: 232 bytes\n",
      "get_ipython: 64 bytes\n",
      "exit: 48 bytes\n",
      "quit: 48 bytes\n",
      "_: 49 bytes\n",
      "__: 49 bytes\n",
      "___: 49 bytes\n",
      "_i: 385 bytes\n",
      "_ii: 341 bytes\n",
      "_iii: 99 bytes\n",
      "_i1: 1634 bytes\n",
      "np: 72 bytes\n",
      "torch: 72 bytes\n",
      "nn: 72 bytes\n",
      "optim: 72 bytes\n",
      "Dataset: 1064 bytes\n",
      "DataLoader: 1472 bytes\n",
      "BertTokenizer: 2008 bytes\n",
      "dts: 72 bytes\n",
      "pd: 72 bytes\n",
      "sns: 72 bytes\n",
      "plt: 72 bytes\n",
      "nltk: 72 bytes\n",
      "re: 72 bytes\n",
      "gc: 72 bytes\n",
      "stopwords: 48 bytes\n",
      "CountVectorizer: 1064 bytes\n",
      "TfidfVectorizer: 1064 bytes\n",
      "WordCloud: 1064 bytes\n",
      "STOPWORDS: 8408 bytes\n",
      "SnowballStemmer: 1064 bytes\n",
      "train_test_split: 136 bytes\n",
      "TfidfTransformer: 1064 bytes\n",
      "MultinomialNB: 1064 bytes\n",
      "OneVsRestClassifier: 1064 bytes\n",
      "LinearSVC: 1064 bytes\n",
      "LogisticRegression: 1064 bytes\n",
      "Pipeline: 1064 bytes\n",
      "MultiLabelBinarizer: 1064 bytes\n",
      "BinaryRelevance: 1064 bytes\n",
      "ClassifierChain: 1064 bytes\n",
      "TomekLinks: 1064 bytes\n",
      "RandomUnderSampler: 1064 bytes\n",
      "BertModel: 1472 bytes\n",
      "f1_score: 136 bytes\n",
      "hamming_loss: 136 bytes\n",
      "accuracy_score: 136 bytes\n",
      "_i2: 100 bytes\n",
      "dataset: 248 bytes\n",
      "_i3: 267 bytes\n",
      "train_dataset: 1606340 bytes\n",
      "val_dataset: 681180 bytes\n",
      "test_dataset: 474769 bytes\n",
      "stop_words: 1488 bytes\n",
      "_i4: 5411 bytes\n",
      "definitions: 360 bytes\n",
      "entailment_con: 64 bytes\n",
      "_i5: 805 bytes\n",
      "BERTClassifier: 1472 bytes\n",
      "learning_rate: 24 bytes\n",
      "num_classes: 28 bytes\n",
      "base_model: 48 bytes\n",
      "loss_function: 48 bytes\n",
      "optimizer: 48 bytes\n",
      "_i6: 1494 bytes\n",
      "CustomDataset: 1064 bytes\n",
      "tokenizer: 48 bytes\n",
      "batch_size: 28 bytes\n",
      "train_custom: 48 bytes\n",
      "train_dataloader: 48 bytes\n",
      "valid_custom: 48 bytes\n",
      "valid_dataloader: 48 bytes\n",
      "_i7: 1872 bytes\n",
      "device: 24 bytes\n",
      "train: 136 bytes\n",
      "_i8: 99 bytes\n",
      "_i9: 783 bytes\n",
      "_i10: 1494 bytes\n",
      "_i11: 1872 bytes\n",
      "_i12: 1516 bytes\n",
      "_i13: 1872 bytes\n",
      "_i14: 765 bytes\n",
      "_i15: 1516 bytes\n",
      "_i16: 1872 bytes\n",
      "_i17: 1494 bytes\n",
      "_i18: 1872 bytes\n",
      "_i19: 341 bytes\n",
      "obj: 232 bytes\n",
      "_i20: 1876 bytes\n",
      "_i21: 99 bytes\n",
      "_i22: 341 bytes\n",
      "_i23: 385 bytes\n",
      "sys: 72 bytes\n",
      "name: 52 bytes\n",
      "value: 52 bytes\n",
      "_i24: 385 bytes\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# Print local variable names with memory space\n",
    "print(\"Local variables:\")\n",
    "for name, value in locals().items():\n",
    "    print(f\"{name}: {sys.getsizeof(value)} bytes\")\n",
    "\n",
    "# Print global variable names with memory space\n",
    "print(\"Global variables:\")\n",
    "for name, value in globals().items():\n",
    "    print(f\"{name}: {sys.getsizeof(value)} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71d3328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
