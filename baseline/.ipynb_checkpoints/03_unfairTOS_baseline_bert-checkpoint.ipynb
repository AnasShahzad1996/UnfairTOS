{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0747e321",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------# Import libraries and datasets #------#\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer\n",
    "import datasets as dts\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import re\n",
    "import gc\n",
    "%matplotlib inline\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from transformers import BertModel,AutoModel\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1bdd8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset lex_glue (/home/anas/.cache/huggingface/datasets/lex_glue/unfair_tos/1.0.0/8a66420941bf6e77a7ddd4da4d3bfb7ba88ef48c1d55302a568ac650a095ca3a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f9fb9b17a6f468d915430062ca6f694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dts.load_dataset('lex_glue','unfair_tos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "938c7242",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.DataFrame.from_dict(dataset[\"train\"])\n",
    "val_dataset = pd.DataFrame.from_dict(dataset[\"validation\"])\n",
    "test_dataset = pd.DataFrame.from_dict(dataset[\"test\"])\n",
    "\n",
    "stop_words = list(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6004daaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "definitions = {\"Limitation of liability\": [\"This clause stipulates that the duty to pay damages is limited or excluded, for certain kind of losses, under certain conditions. \"]\n",
    "               , \"Unilateral termination\": [\"This clause gives provider the right to suspend and/or terminate the service and/or the contract, and sometimes details the circumstances under which the provider claims to have a right to do so.\"]\n",
    "               , \"Unilateral change\": [\"This clause specifies the conditions under which the service provider could amend and modify the terms of service and/or the service itself.\"]\n",
    "               , \"Content removal\": [\"This clause gives the provider a right to modify/delete userâ€™s content, including in-app purchases, and sometimes specifies the conditions under which the service provider may do so.\"]\n",
    "               , \"Contract by using\": [\"This clause stipulates that the consumer is bound by the terms of use of a specific service, simply by using the service, without even being required to mark that he or she has read and accepted them.\"]\n",
    "               , \"Choice of law\": [\"This clause specifies what law will govern the contract, meaning also what law will be applied in potential adjudication of a dispute arising under the contract.\"]\n",
    "               , \"Jurisdiction\": [\"This selection clause requires or allows the parties to resolve their disputes through an arbitration process, before the case could go to court.\"]\n",
    "               , \"Arbitration\": [\"This forum selection clause requires or allows the parties to resolve their disputes through an arbitration process, before the case could go to court however, such a clause may or may not specify that arbitration should occur within a specific jurisdiction. \"]}\n",
    "\n",
    "entailment_con = [\"entails\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588159dd",
   "metadata": {},
   "source": [
    "### Default with 8 + 1 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fd4e005f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpaueb/legal-bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTClassifier(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (fc): Linear(in_features=768, out_features=8, bias=True)\n",
      "  (sig): GELU(approximate='none')\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(\"nlpaueb/legal-bert-base-uncased\")\n",
    "        #self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc = nn.Linear(768, 8)\n",
    "        self.sig = torch.nn.GELU()\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        _ , pooled_output = self.bert(input_ids=input_ids, attention_mask =attention_mask,return_dict=False)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.fc(pooled_output)\n",
    "        prediction = self.sig(logits)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "learning_rate = 3e-5\n",
    "num_classes = 8\n",
    "base_model = BERTClassifier(num_classes)\n",
    "#loss_function = nn.CrossEntropyLoss()\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(base_model.parameters(), lr=learning_rate)\n",
    "print (base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "698e897f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataset,num_classes,tokenizer):\n",
    "        \n",
    "        self.dataset = dataset\n",
    "        self.texts = self.dataset[\"text\"]\n",
    "        self.labels = self.dataset[\"labels\"]\n",
    "        self.num_classes = num_classes\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text = self.texts[index]\n",
    "        label = self.labels[index]\n",
    "        \n",
    "        # Tokenize the text\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=64,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        input_ids = inputs['input_ids'].squeeze()\n",
    "        attention_mask = inputs['attention_mask'].squeeze()\n",
    "        #print (\"original label: \",label)\n",
    "        # Convert label to one-hot encoding\n",
    "        multi_label = torch.zeros(self.num_classes, dtype=torch.float32)\n",
    "        multi_label[label] = 1\n",
    "        #print (\"one hot multi : \",multi_label)\n",
    "        return {'input_ids':input_ids, 'attention_mask':attention_mask, 'multi_label':multi_label}\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "batch_size = 8\n",
    "train_custom = CustomDataset(train_dataset, num_classes,tokenizer)\n",
    "train_dataloader = DataLoader(train_custom, batch_size=batch_size, shuffle=True)\n",
    "valid_custom = CustomDataset(val_dataset, num_classes,tokenizer)\n",
    "val_dataloader = DataLoader(valid_custom, batch_size=batch_size, shuffle=True)\n",
    "def find_metrics(targets,prediction):\n",
    "    final_pred = ((torch.sigmoid(prediction) >= 0.5) * 1.0)\n",
    "    np_tar = targets.cpu().detach().numpy()\n",
    "    np_pred = final_pred.cpu().detach().numpy()\n",
    "    \n",
    "    avg_f1_mic = f1_score(np_tar.flatten(), np_pred.flatten(), average='micro',zero_division=0)\n",
    "    avg_f1_mac = f1_score(np_tar, np_pred, average='macro',zero_division=1)\n",
    "    avg_acc = accuracy_score(np_tar, np_pred)\n",
    "    del np_tar\n",
    "    del np_pred\n",
    "    del final_pred\n",
    "    return avg_f1_mic, avg_f1_mac, avg_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "63e68bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 ,Iteration : 1, training loss: 1.6184 , running loss:1.6184499263763428 (0.875, 0.875, 0.0)\n",
      "Epoch : 1 ,Iteration : 2, training loss: 2.1937 , running loss:1.9060617685317993 (0.875, 0.875, 0.0)\n",
      "Epoch : 2 ,Iteration : 3, training loss: 1.5850 , running loss:1.7990306615829468 (0.75, 0.75, 0.0)\n",
      "Epoch : 3 ,Iteration : 4, training loss: 1.8905 , running loss:1.8219015300273895 (0.875, 0.875, 0.0)\n",
      "Epoch : 4 ,Iteration : 5, training loss: 1.6284 , running loss:1.7831977367401124 (0.75, 0.75, 0.0)\n",
      "Epoch : 5 ,Iteration : 6, training loss: 1.6870 , running loss:1.7671671311060588 (0.75, 0.75, 0.0)\n",
      "Epoch : 6 ,Iteration : 7, training loss: 1.5712 , running loss:1.7391750812530518 (0.875, 0.875, 0.0)\n",
      "Epoch : 7 ,Iteration : 8, training loss: 1.4853 , running loss:1.707445204257965 (1.0, 1.0, 1.0)\n",
      "Epoch : 8 ,Iteration : 9, training loss: 1.4633 , running loss:1.680318898624844 (0.875, 0.875, 0.0)\n",
      "Epoch : 9 ,Iteration : 10, training loss: 1.4691 , running loss:1.6592008233070374 (1.0, 1.0, 1.0)\n",
      "Epoch : 10 ,Iteration : 11, training loss: 1.4712 , running loss:1.6421129595149646 (1.0, 1.0, 1.0)\n",
      "Epoch : 11 ,Iteration : 12, training loss: 1.4459 , running loss:1.6257626712322235 (1.0, 1.0, 1.0)\n",
      "Epoch : 12 ,Iteration : 13, training loss: 1.4443 , running loss:1.611807080415579 (1.0, 1.0, 1.0)\n",
      "Epoch : 13 ,Iteration : 14, training loss: 1.4260 , running loss:1.5985349757330758 (1.0, 1.0, 1.0)\n",
      "Epoch : 14 ,Iteration : 15, training loss: 1.4164 , running loss:1.5863911946614584 (1.0, 1.0, 1.0)\n",
      "Epoch : 15 ,Iteration : 16, training loss: 1.4705 , running loss:1.5791469067335129 (1.0, 1.0, 1.0)\n",
      "Epoch : 16 ,Iteration : 17, training loss: 1.4179 , running loss:1.569660600493936 (1.0, 1.0, 1.0)\n",
      "Epoch : 17 ,Iteration : 18, training loss: 1.4284 , running loss:1.561812652481927 (1.0, 1.0, 1.0)\n",
      "Epoch : 18 ,Iteration : 19, training loss: 1.4228 , running loss:1.5544963761379844 (1.0, 1.0, 1.0)\n",
      "eval epoch\n",
      "Epoch : 19 ,Iteration : 20, training loss: 1.4048 , running loss:1.547013920545578 (1.0, 1.0, 1.0)\n",
      "Epoch : 20 ,Iteration : 21, training loss: 1.4055 , running loss:1.5363640010356903 (1.0, 1.0, 1.0)\n",
      "Epoch : 21 ,Iteration : 22, training loss: 1.4174 , running loss:1.4975519478321075 (1.0, 1.0, 1.0)\n",
      "Epoch : 22 ,Iteration : 23, training loss: 1.4017 , running loss:1.4883862257003784 (1.0, 1.0, 1.0)\n",
      "Epoch : 23 ,Iteration : 24, training loss: 1.4110 , running loss:1.4644106149673461 (1.0, 1.0, 1.0)\n",
      "Epoch : 24 ,Iteration : 25, training loss: 1.4058 , running loss:1.4532806158065796 (1.0, 1.0, 1.0)\n",
      "Epoch : 25 ,Iteration : 26, training loss: 1.4371 , running loss:1.4407837867736817 (1.0, 1.0, 1.0)\n",
      "Epoch : 26 ,Iteration : 27, training loss: 1.4020 , running loss:1.4323249638080597 (1.0, 1.0, 1.0)\n",
      "Epoch : 27 ,Iteration : 28, training loss: 1.4006 , running loss:1.4280885577201843 (1.0, 1.0, 1.0)\n",
      "Epoch : 28 ,Iteration : 29, training loss: 1.3987 , running loss:1.4248587548732758 (1.0, 1.0, 1.0)\n",
      "Epoch : 29 ,Iteration : 30, training loss: 1.4013 , running loss:1.4214651584625244 (1.0, 1.0, 1.0)\n",
      "Epoch : 30 ,Iteration : 31, training loss: 1.3996 , running loss:1.4178827345371245 (1.0, 1.0, 1.0)\n",
      "Epoch : 31 ,Iteration : 32, training loss: 1.3999 , running loss:1.4155797839164734 (1.0, 1.0, 1.0)\n",
      "Epoch : 32 ,Iteration : 33, training loss: 1.4100 , running loss:1.413864052295685 (1.0, 1.0, 1.0)\n",
      "Epoch : 33 ,Iteration : 34, training loss: 1.4050 , running loss:1.4128121256828308 (1.0, 1.0, 1.0)\n",
      "Epoch : 34 ,Iteration : 35, training loss: 1.4329 , running loss:1.413638710975647 (1.0, 1.0, 1.0)\n",
      "Epoch : 35 ,Iteration : 36, training loss: 1.4183 , running loss:1.4110289633274078 (1.0, 1.0, 1.0)\n",
      "Epoch : 36 ,Iteration : 37, training loss: 1.4393 , running loss:1.4121002197265624 (1.0, 1.0, 1.0)\n",
      "Epoch : 37 ,Iteration : 38, training loss: 1.4070 , running loss:1.4110320270061494 (1.0, 1.0, 1.0)\n",
      "Epoch : 38 ,Iteration : 39, training loss: 1.3941 , running loss:1.409598058462143 (1.0, 1.0, 1.0)\n",
      "eval epoch\n",
      "Epoch : 39 ,Iteration : 40, training loss: 1.3951 , running loss:1.4091102004051208 (1.0, 1.0, 1.0)\n",
      "Epoch : 40 ,Iteration : 41, training loss: 1.4032 , running loss:1.4089997947216033 (1.0, 1.0, 1.0)\n",
      "Epoch : 41 ,Iteration : 42, training loss: 1.3977 , running loss:1.408014714717865 (1.0, 1.0, 1.0)\n",
      "Epoch : 42 ,Iteration : 43, training loss: 1.3965 , running loss:1.407755011320114 (1.0, 1.0, 1.0)\n",
      "Epoch : 43 ,Iteration : 44, training loss: 1.4203 , running loss:1.4082219123840332 (1.0, 1.0, 1.0)\n",
      "Epoch : 44 ,Iteration : 45, training loss: 1.4040 , running loss:1.4081336915493012 (1.0, 1.0, 1.0)\n",
      "Epoch : 45 ,Iteration : 46, training loss: 1.3937 , running loss:1.4059649109840393 (1.0, 1.0, 1.0)\n",
      "Epoch : 46 ,Iteration : 47, training loss: 1.4075 , running loss:1.4062356293201446 (1.0, 1.0, 1.0)\n",
      "Epoch : 47 ,Iteration : 48, training loss: 1.4033 , running loss:1.4063692212104797 (1.0, 1.0, 1.0)\n",
      "Epoch : 48 ,Iteration : 49, training loss: 1.3936 , running loss:1.406113338470459 (1.0, 1.0, 1.0)\n",
      "Epoch : 49 ,Iteration : 50, training loss: 1.3970 , running loss:1.4059021413326263 (1.0, 1.0, 1.0)\n",
      "Epoch : 50 ,Iteration : 51, training loss: 1.4072 , running loss:1.40628120303154 (1.0, 1.0, 1.0)\n",
      "Epoch : 51 ,Iteration : 52, training loss: 1.3963 , running loss:1.4061060130596161 (1.0, 1.0, 1.0)\n",
      "Epoch : 52 ,Iteration : 53, training loss: 1.4016 , running loss:1.4056841731071472 (1.0, 1.0, 1.0)\n",
      "Epoch : 53 ,Iteration : 54, training loss: 1.4592 , running loss:1.4083945453166962 (1.0, 1.0, 1.0)\n",
      "Epoch : 54 ,Iteration : 55, training loss: 1.4017 , running loss:1.406832605600357 (1.0, 1.0, 1.0)\n",
      "Epoch : 55 ,Iteration : 56, training loss: 1.4215 , running loss:1.4069951176643372 (1.0, 1.0, 1.0)\n",
      "Epoch : 56 ,Iteration : 57, training loss: 1.3954 , running loss:1.404797899723053 (1.0, 1.0, 1.0)\n",
      "Epoch : 57 ,Iteration : 58, training loss: 1.4438 , running loss:1.406635767221451 (1.0, 1.0, 1.0)\n",
      "Epoch : 58 ,Iteration : 59, training loss: 1.3962 , running loss:1.4067379891872407 (1.0, 1.0, 1.0)\n",
      "eval epoch\n",
      "Epoch : 59 ,Iteration : 60, training loss: 1.4011 , running loss:1.4070370495319366 (1.0, 1.0, 1.0)\n",
      "Epoch : 60 ,Iteration : 61, training loss: 1.4119 , running loss:1.4074696600437164 (1.0, 1.0, 1.0)\n",
      "Epoch : 61 ,Iteration : 62, training loss: 1.4017 , running loss:1.407666552066803 (1.0, 1.0, 1.0)\n",
      "Epoch : 62 ,Iteration : 63, training loss: 1.3936 , running loss:1.4075239181518555 (1.0, 1.0, 1.0)\n",
      "Epoch : 63 ,Iteration : 64, training loss: 1.3945 , running loss:1.406231302022934 (1.0, 1.0, 1.0)\n",
      "Epoch : 64 ,Iteration : 65, training loss: 1.3933 , running loss:1.4056959986686706 (1.0, 1.0, 1.0)\n",
      "Epoch : 65 ,Iteration : 66, training loss: 1.3935 , running loss:1.4056871056556701 (1.0, 1.0, 1.0)\n",
      "Epoch : 66 ,Iteration : 67, training loss: 1.4520 , running loss:1.4079135298728942 (1.0, 1.0, 1.0)\n",
      "Epoch : 67 ,Iteration : 68, training loss: 1.4031 , running loss:1.4079022824764251 (1.0, 1.0, 1.0)\n",
      "Epoch : 68 ,Iteration : 69, training loss: 1.3929 , running loss:1.4078691124916076 (1.0, 1.0, 1.0)\n",
      "Epoch : 69 ,Iteration : 70, training loss: 1.3935 , running loss:1.4076914489269257 (1.0, 1.0, 1.0)\n",
      "Epoch : 70 ,Iteration : 71, training loss: 1.4074 , running loss:1.4077013611793519 (1.0, 1.0, 1.0)\n",
      "Epoch : 71 ,Iteration : 72, training loss: 1.4272 , running loss:1.4092427253723145 (1.0, 1.0, 1.0)\n",
      "Epoch : 72 ,Iteration : 73, training loss: 1.3984 , running loss:1.409081482887268 (1.0, 1.0, 1.0)\n",
      "Epoch : 73 ,Iteration : 74, training loss: 1.4490 , running loss:1.4085734844207765 (1.0, 1.0, 1.0)\n",
      "Epoch : 74 ,Iteration : 75, training loss: 1.3928 , running loss:1.4081321120262147 (1.0, 1.0, 1.0)\n",
      "Epoch : 75 ,Iteration : 76, training loss: 1.4292 , running loss:1.4085143327713012 (1.0, 1.0, 1.0)\n",
      "Epoch : 76 ,Iteration : 77, training loss: 1.3964 , running loss:1.4085654377937318 (1.0, 1.0, 1.0)\n",
      "Epoch : 77 ,Iteration : 78, training loss: 1.4087 , running loss:1.406810462474823 (1.0, 1.0, 1.0)\n",
      "Epoch : 78 ,Iteration : 79, training loss: 1.4252 , running loss:1.408262699842453 (1.0, 1.0, 1.0)\n",
      "eval epoch\n",
      "Epoch : 79 ,Iteration : 80, training loss: 1.3963 , running loss:1.4080246448516847 (1.0, 1.0, 1.0)\n",
      "Epoch : 80 ,Iteration : 81, training loss: 1.4003 , running loss:1.4074471056461335 (1.0, 1.0, 1.0)\n",
      "Epoch : 81 ,Iteration : 82, training loss: 1.3927 , running loss:1.4069972276687621 (1.0, 1.0, 1.0)\n",
      "Epoch : 82 ,Iteration : 83, training loss: 1.4034 , running loss:1.407489162683487 (1.0, 1.0, 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 83 ,Iteration : 84, training loss: 1.3963 , running loss:1.4075821936130524 (1.0, 1.0, 1.0)\n",
      "Epoch : 84 ,Iteration : 85, training loss: 1.4088 , running loss:1.4083540916442872 (1.0, 1.0, 1.0)\n",
      "Epoch : 85 ,Iteration : 86, training loss: 1.4261 , running loss:1.409983789920807 (1.0, 1.0, 1.0)\n",
      "Epoch : 86 ,Iteration : 87, training loss: 1.3923 , running loss:1.407001680135727 (1.0, 1.0, 1.0)\n",
      "Epoch : 87 ,Iteration : 88, training loss: 1.3982 , running loss:1.4067601144313813 (1.0, 1.0, 1.0)\n",
      "Epoch : 88 ,Iteration : 89, training loss: 1.3960 , running loss:1.4069125294685363 (1.0, 1.0, 1.0)\n",
      "Epoch : 89 ,Iteration : 90, training loss: 1.4050 , running loss:1.407490473985672 (1.0, 1.0, 1.0)\n",
      "Epoch : 90 ,Iteration : 91, training loss: 1.4073 , running loss:1.4074879586696625 (1.0, 1.0, 1.0)\n",
      "Epoch : 91 ,Iteration : 92, training loss: 1.4480 , running loss:1.4085281789302826 (1.0, 1.0, 1.0)\n",
      "Epoch : 92 ,Iteration : 93, training loss: 1.3930 , running loss:1.4082599461078644 (1.0, 1.0, 1.0)\n",
      "Epoch : 93 ,Iteration : 94, training loss: 1.4452 , running loss:1.4080714643001557 (1.0, 1.0, 1.0)\n",
      "Epoch : 94 ,Iteration : 95, training loss: 1.4044 , running loss:1.4086511135101318 (1.0, 1.0, 1.0)\n",
      "Epoch : 95 ,Iteration : 96, training loss: 1.3950 , running loss:1.4069434523582458 (1.0, 1.0, 1.0)\n",
      "Epoch : 96 ,Iteration : 97, training loss: 1.3979 , running loss:1.4070197761058807 (1.0, 1.0, 1.0)\n",
      "Epoch : 97 ,Iteration : 98, training loss: 1.4101 , running loss:1.4070906162261962 (1.0, 1.0, 1.0)\n",
      "Epoch : 98 ,Iteration : 99, training loss: 1.4270 , running loss:1.4071803152561189 (1.0, 1.0, 1.0)\n",
      "eval epoch\n",
      "Epoch : 99 ,Iteration : 100, training loss: 1.3933 , running loss:1.4070294678211213 (1.0, 1.0, 1.0)\n",
      "Epoch : 100 ,Iteration : 101, training loss: 1.4087 , running loss:1.4074454605579376 (1.0, 1.0, 1.0)\n",
      "Epoch : 101 ,Iteration : 102, training loss: 1.3958 , running loss:1.4076042115688323 (1.0, 1.0, 1.0)\n",
      "Epoch : 102 ,Iteration : 103, training loss: 1.4199 , running loss:1.4084284365177155 (1.0, 1.0, 1.0)\n",
      "Epoch : 103 ,Iteration : 104, training loss: 1.3985 , running loss:1.408537071943283 (1.0, 1.0, 1.0)\n",
      "Epoch : 104 ,Iteration : 105, training loss: 1.4032 , running loss:1.408257830142975 (1.0, 1.0, 1.0)\n",
      "Epoch : 105 ,Iteration : 106, training loss: 1.4290 , running loss:1.4084004282951355 (1.0, 1.0, 1.0)\n",
      "Epoch : 106 ,Iteration : 107, training loss: 1.3929 , running loss:1.4084264755249023 (1.0, 1.0, 1.0)\n",
      "Epoch : 107 ,Iteration : 108, training loss: 1.4347 , running loss:1.4102490603923798 (1.0, 1.0, 1.0)\n",
      "Epoch : 108 ,Iteration : 109, training loss: 1.4637 , running loss:1.4136375486850739 (1.0, 1.0, 1.0)\n",
      "Epoch : 109 ,Iteration : 110, training loss: 1.4131 , running loss:1.4140379548072814 (1.0, 1.0, 1.0)\n",
      "Epoch : 110 ,Iteration : 111, training loss: 1.4102 , running loss:1.4141799628734588 (1.0, 1.0, 1.0)\n",
      "Epoch : 111 ,Iteration : 112, training loss: 1.4204 , running loss:1.4128012239933014 (1.0, 1.0, 1.0)\n",
      "Epoch : 112 ,Iteration : 113, training loss: 1.3989 , running loss:1.4130965232849122 (1.0, 1.0, 1.0)\n",
      "Epoch : 113 ,Iteration : 114, training loss: 1.3929 , running loss:1.4104799807071686 (1.0, 1.0, 1.0)\n",
      "Epoch : 114 ,Iteration : 115, training loss: 1.3973 , running loss:1.4101221919059754 (1.0, 1.0, 1.0)\n",
      "Epoch : 115 ,Iteration : 116, training loss: 1.3947 , running loss:1.4101059794425965 (1.0, 1.0, 1.0)\n",
      "Epoch : 116 ,Iteration : 117, training loss: 1.3921 , running loss:1.4098160922527314 (1.0, 1.0, 1.0)\n",
      "Epoch : 117 ,Iteration : 118, training loss: 1.4416 , running loss:1.411388248205185 (1.0, 1.0, 1.0)\n",
      "Epoch : 118 ,Iteration : 119, training loss: 1.3969 , running loss:1.4098828792572022 (1.0, 1.0, 1.0)\n",
      "eval epoch\n",
      "Epoch : 119 ,Iteration : 120, training loss: 1.3913 , running loss:1.409781014919281 (1.0, 1.0, 1.0)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6746/2183262614.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moverfit_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mone_example\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_6746/2183262614.py\u001b[0m in \u001b[0;36moverfit_one\u001b[0;34m(base_model, fit_example)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# freeing up excess memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# overfitting on one example:\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "base_model.to(device)\n",
    "one_example = None\n",
    "while one_example == None:\n",
    "    curr_batch = next(iter(train_dataloader))\n",
    "    if torch.sum(curr_batch[\"multi_label\"]) > 1:\n",
    "        one_example = curr_batch\n",
    "\n",
    "def overfit_one(base_model,fit_example):\n",
    "    num_epochs = 1000\n",
    "    running_loss = []\n",
    "    iteration = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        base_model.train()  # Set the model to training mode            \n",
    "        \n",
    "        iteration +=1\n",
    "        if iteration % 20 == 0:\n",
    "            print (\"eval epoch\")\n",
    "            base_model.eval()\n",
    "        input_ids = fit_example['input_ids'].to(device)\n",
    "        attention_mask = fit_example['attention_mask'].to(device)\n",
    "        targets = fit_example['multi_label'].to(device)\n",
    "\n",
    "\n",
    "        outputs = base_model(input_ids,attention_mask)\n",
    "        loss = loss_function(outputs.to(device), targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #print (iteration)\n",
    "        running_loss.append(loss.item())\n",
    "        if len(running_loss) > 20:\n",
    "            running_loss.pop(0)\n",
    "        #print (outputs,\"||||\",targets)\n",
    "        #print (\"debug metrics : \",find_metrics(targets,targets))\n",
    "        print (f\"Epoch : {epoch} ,Iteration : {iteration}, training loss: {loss:.4f} , running loss:{sum(running_loss)/len(running_loss)}\",find_metrics(targets,outputs))\n",
    "\n",
    "        if iteration % 20 == 0:\n",
    "            base_model.train()\n",
    "\n",
    "        \n",
    "        # freeing up excess memory\n",
    "        del loss, outputs\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    return base_model\n",
    "\n",
    "base_model = overfit_one(base_model,one_example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d35c015f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 ,Iteration : 0, training loss: 0.6343 , running loss:0.6342571377754211 (0.0, 0.38983050847457623, 0.0, 0.0, 0.0)\n",
      "Validation loss : 0.5753532129421569 and metrics(micro,macro,acc) :(0.026863226863226862, 0.4281826537530369, 0.01010989010989011, 0.026863226862757734, 0.008497135698349046)\n",
      "Epoch : 0 ,Iteration : 1, training loss: 0.5940 , running loss:0.614126592874527 (0.0, 0.40495867768595045, 0.0, 0.0, 0.0)\n",
      "Epoch : 0 ,Iteration : 2, training loss: 0.5730 , running loss:0.6004253029823303 (0.0, 0.41463414634146345, 0.0, 0.0, 0.0)\n",
      "Epoch : 0 ,Iteration : 3, training loss: 0.5347 , running loss:0.5840025097131729 (0.11111111111111112, 0.49206349206349204, 0.125, 0.11111111111061728, 0.024691358024691353)\n",
      "Epoch : 0 ,Iteration : 4, training loss: 0.4699 , running loss:0.5611724853515625 (0.5, 0.71875, 0.5, 0.49999999999949996, 0.07407407407407407)\n",
      "Epoch : 0 ,Iteration : 5, training loss: 0.4463 , running loss:0.5420268177986145 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 6, training loss: 0.4216 , running loss:0.5248164364269802 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 7, training loss: 0.4153 , running loss:0.5111223720014095 (0.75, 0.859375, 0.75, 0.7499999999995, 0.09523809523809523)\n",
      "Epoch : 0 ,Iteration : 8, training loss: 0.3639 , running loss:0.4947597119543288 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 9, training loss: 0.3713 , running loss:0.48241526186466216 (0.75, 0.859375, 0.75, 0.7499999999995, 0.09523809523809523)\n",
      "Epoch : 0 ,Iteration : 10, training loss: 0.3508 , running loss:0.47044695778326556 (0.75, 0.859375, 0.75, 0.7499999999995, 0.09523809523809523)\n",
      "Validation loss : 0.31307916243871053 and metrics(micro,macro,acc) :(0.895163055373167, 0.9409984211199691, 0.8989010989010989, 0.8951630553726669, 0.1051954732510288)\n",
      "Epoch : 0 ,Iteration : 11, training loss: 0.3030 , running loss:0.4564896722634633 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 12, training loss: 0.2915 , running loss:0.44379745309169477 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 13, training loss: 0.2997 , running loss:0.4335035000528608 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 14, training loss: 0.2830 , running loss:0.42346772948900857 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 15, training loss: 0.2960 , running loss:0.4155005309730768 (0.75, 0.859375, 0.75, 0.7499999999995, 0.09523809523809523)\n",
      "Epoch : 0 ,Iteration : 16, training loss: 0.2426 , running loss:0.40532905038665323 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 17, training loss: 0.3010 , running loss:0.3995325201087528 (0.7058823529411765, 0.8332561371005095, 0.75, 0.7058823529406782, 0.09523809523809523)\n",
      "Epoch : 0 ,Iteration : 18, training loss: 0.2790 , running loss:0.3931904529270373 (0.75, 0.859375, 0.75, 0.7499999999995, 0.09523809523809523)\n",
      "Epoch : 0 ,Iteration : 19, training loss: 0.2720 , running loss:0.3871298015117645 (0.75, 0.859375, 0.75, 0.7499999999995, 0.09523809523809523)\n",
      "Epoch : 0 ,Iteration : 20, training loss: 0.2206 , running loss:0.3664468377828598 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Validation loss : 0.21580660484339062 and metrics(micro,macro,acc) :(0.895163055373167, 0.9409984211199691, 0.8989010989010989, 0.8951630553726669, 0.1051954732510288)\n",
      "Epoch : 0 ,Iteration : 21, training loss: 0.2102 , running loss:0.34725779592990874 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 22, training loss: 0.2001 , running loss:0.3286129988729954 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 23, training loss: 0.1986 , running loss:0.3118084125220776 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 24, training loss: 0.1878 , running loss:0.2977078013122082 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 25, training loss: 0.1788 , running loss:0.28433391973376276 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 26, training loss: 0.1850 , running loss:0.2725069008767605 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 27, training loss: 0.1771 , running loss:0.2605969272553921 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 28, training loss: 0.2646 , running loss:0.2556346856057644 (0.5882352941176471, 0.7665585919407133, 0.625, 0.5882352941171487, 0.08547008547008547)\n",
      "Epoch : 0 ,Iteration : 29, training loss: 0.1551 , running loss:0.24482597187161445 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 30, training loss: 0.2497 , running loss:0.23977398052811622 (0.625, 0.7890625, 0.625, 0.6249999999995, 0.08547008547008547)\n",
      "Validation loss : 0.16492893721973687 and metrics(micro,macro,acc) :(0.895163055373167, 0.9409984211199691, 0.8989010989010989, 0.8951630553726669, 0.1051954732510288)\n",
      "Epoch : 0 ,Iteration : 31, training loss: 0.1723 , running loss:0.23324162140488625 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 32, training loss: 0.1708 , running loss:0.22720917612314223 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 33, training loss: 0.1705 , running loss:0.2207477793097496 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 34, training loss: 0.1612 , running loss:0.21465811431407927 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 35, training loss: 0.1638 , running loss:0.20804719626903534 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 36, training loss: 0.1282 , running loss:0.2023293688893318 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 37, training loss: 0.1237 , running loss:0.19346412681043149 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 38, training loss: 0.1173 , running loss:0.18537515066564084 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 39, training loss: 0.1468 , running loss:0.17911712042987346 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 40, training loss: 0.1138 , running loss:0.1737768318504095 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Validation loss : 0.13531363337186345 and metrics(micro,macro,acc) :(0.895163055373167, 0.9409984211199691, 0.8989010989010989, 0.8951630553726669, 0.1051954732510288)\n",
      "Epoch : 0 ,Iteration : 41, training loss: 0.1822 , running loss:0.17237570621073245 (0.75, 0.859375, 0.75, 0.7499999999995, 0.09523809523809523)\n",
      "Epoch : 0 ,Iteration : 42, training loss: 0.1074 , running loss:0.16774097867310048 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 43, training loss: 0.1093 , running loss:0.16327216662466526 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 44, training loss: 0.2308 , running loss:0.16542030237615107 (0.5882352941176471, 0.7665585919407133, 0.625, 0.5882352941171487, 0.08547008547008547)\n",
      "Epoch : 0 ,Iteration : 45, training loss: 0.1008 , running loss:0.16151922680437564 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 46, training loss: 0.1738 , running loss:0.1609595227986574 (0.75, 0.859375, 0.75, 0.7499999999995, 0.09523809523809523)\n",
      "Epoch : 0 ,Iteration : 47, training loss: 0.1649 , running loss:0.16035184375941752 (0.823529411764706, 0.8999536822603057, 0.875, 0.8235294117642077, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 48, training loss: 0.0956 , running loss:0.15190278328955173 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 49, training loss: 0.0942 , running loss:0.14885612465441228 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 50, training loss: 0.0917 , running loss:0.14095372073352336 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Validation loss : 0.1168741029344107 and metrics(micro,macro,acc) :(0.895163055373167, 0.9409984211199691, 0.8989010989010989, 0.8951630553726669, 0.1051954732510288)\n",
      "Epoch : 0 ,Iteration : 51, training loss: 0.0893 , running loss:0.1368055295199156 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 ,Iteration : 52, training loss: 0.1609 , running loss:0.13630967028439045 (0.75, 0.859375, 0.75, 0.7499999999995, 0.09523809523809523)\n",
      "Epoch : 0 ,Iteration : 53, training loss: 0.0858 , running loss:0.13207568302750589 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 54, training loss: 0.0872 , running loss:0.12837861701846123 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 55, training loss: 0.1128 , running loss:0.12583119608461857 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 56, training loss: 0.1222 , running loss:0.12552982419729233 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 57, training loss: 0.1231 , running loss:0.12550104968249798 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 58, training loss: 0.1167 , running loss:0.1254751469939947 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 59, training loss: 0.1144 , running loss:0.12385404482483864 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 60, training loss: 0.1188 , running loss:0.1241040587425232 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Validation loss : 0.10459709313877842 and metrics(micro,macro,acc) :(0.895163055373167, 0.9409984211199691, 0.8989010989010989, 0.8951630553726669, 0.1051954732510288)\n",
      "Epoch : 0 ,Iteration : 61, training loss: 0.1117 , running loss:0.12057829275727272 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 62, training loss: 0.0765 , running loss:0.1190340831875801 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 63, training loss: 0.1114 , running loss:0.11913904026150704 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 64, training loss: 0.1537 , running loss:0.11528283059597015 (0.75, 0.859375, 0.75, 0.7499999999995, 0.09523809523809523)\n",
      "Epoch : 0 ,Iteration : 65, training loss: 0.1100 , running loss:0.1157429613173008 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 66, training loss: 0.1438 , running loss:0.11424041241407394 (0.75, 0.859375, 0.75, 0.7499999999995, 0.09523809523809523)\n",
      "Epoch : 0 ,Iteration : 67, training loss: 0.0694 , running loss:0.10946661829948426 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 68, training loss: 0.0659 , running loss:0.10798218958079815 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 69, training loss: 0.1474 , running loss:0.11064200289547443 (0.75, 0.859375, 0.75, 0.7499999999995, 0.09523809523809523)\n",
      "Epoch : 0 ,Iteration : 70, training loss: 0.1924 , running loss:0.1156779456883669 (0.7058823529411765, 0.8332561371005095, 0.75, 0.7058823529406782, 0.09523809523809523)\n",
      "Validation loss : 0.09627175163804438 and metrics(micro,macro,acc) :(0.895163055373167, 0.9409984211199691, 0.8989010989010989, 0.8951630553726669, 0.1051954732510288)\n",
      "Epoch : 0 ,Iteration : 71, training loss: 0.0629 , running loss:0.11435561403632163 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 72, training loss: 0.0647 , running loss:0.10954509451985359 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 73, training loss: 0.1004 , running loss:0.11027852781116962 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 74, training loss: 0.0583 , running loss:0.10883139614015817 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 75, training loss: 0.1450 , running loss:0.11043810825794935 (0.75, 0.859375, 0.75, 0.7499999999995, 0.09523809523809523)\n",
      "Epoch : 0 ,Iteration : 76, training loss: 0.1003 , running loss:0.10934182796627283 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 77, training loss: 0.0587 , running loss:0.1061190104112029 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 78, training loss: 0.1026 , running loss:0.10541261155158281 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 79, training loss: 0.0573 , running loss:0.10255760215222835 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 80, training loss: 0.0948 , running loss:0.10135743543505668 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Validation loss : 0.09092603826470542 and metrics(micro,macro,acc) :(0.895163055373167, 0.9409984211199691, 0.8989010989010989, 0.8951630553726669, 0.1051954732510288)\n",
      "Epoch : 0 ,Iteration : 81, training loss: 0.0949 , running loss:0.10051923841238022 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 82, training loss: 0.0530 , running loss:0.0993427911773324 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 83, training loss: 0.1481 , running loss:0.10118185449391603 (0.75, 0.859375, 0.75, 0.7499999999995, 0.09523809523809523)\n",
      "Epoch : 0 ,Iteration : 84, training loss: 0.0997 , running loss:0.0984828257933259 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 85, training loss: 0.0947 , running loss:0.09771977048367261 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 86, training loss: 0.0999 , running loss:0.09552622307091951 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 87, training loss: 0.0922 , running loss:0.09666570071130991 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 88, training loss: 0.0495 , running loss:0.09584378655999899 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 89, training loss: 0.0482 , running loss:0.09088232833892107 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 90, training loss: 0.0480 , running loss:0.08366028126329184 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Validation loss : 0.08525444463941088 and metrics(micro,macro,acc) :(0.895163055373167, 0.9409984211199691, 0.8989010989010989, 0.8951630553726669, 0.1051954732510288)\n",
      "Epoch : 0 ,Iteration : 91, training loss: 0.0935 , running loss:0.08518928829580545 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 92, training loss: 0.0451 , running loss:0.08420629035681486 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 93, training loss: 0.1660 , running loss:0.08748268093913794 (0.75, 0.859375, 0.75, 0.7499999999995, 0.09523809523809523)\n",
      "Epoch : 0 ,Iteration : 94, training loss: 0.0915 , running loss:0.0891448337584734 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 95, training loss: 0.0458 , running loss:0.08418819699436426 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 96, training loss: 0.2003 , running loss:0.08919109869748354 (0.625, 0.7890625, 0.625, 0.6249999999995, 0.08547008547008547)\n",
      "Epoch : 0 ,Iteration : 97, training loss: 0.1318 , running loss:0.09284867253154516 (0.75, 0.859375, 0.75, 0.7499999999995, 0.09523809523809523)\n",
      "Epoch : 0 ,Iteration : 98, training loss: 0.0434 , running loss:0.08988927248865367 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 99, training loss: 0.0922 , running loss:0.09163507409393787 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 100, training loss: 0.0961 , running loss:0.09170115254819393 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Validation loss : 0.08195739670803673 and metrics(micro,macro,acc) :(0.895163055373167, 0.9409984211199691, 0.8989010989010989, 0.8951630553726669, 0.1051954732510288)\n",
      "Epoch : 0 ,Iteration : 101, training loss: 0.0425 , running loss:0.089079250395298 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 102, training loss: 0.0401 , running loss:0.08843373265117407 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 103, training loss: 0.0942 , running loss:0.08573730569332838 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 ,Iteration : 104, training loss: 0.1860 , running loss:0.09005487617105246 (0.7058823529411765, 0.8332561371005095, 0.75, 0.7058823529406782, 0.09523809523809523)\n",
      "Epoch : 0 ,Iteration : 105, training loss: 0.0376 , running loss:0.08719795253127813 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 106, training loss: 0.1372 , running loss:0.0890637831762433 (0.823529411764706, 0.8999536822603057, 0.875, 0.8235294117642077, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 107, training loss: 0.0893 , running loss:0.08891997430473567 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 108, training loss: 0.0396 , running loss:0.08842589240521193 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 109, training loss: 0.1871 , running loss:0.09537457320839167 (0.7777777777777777, 0.873015873015873, 0.875, 0.7777777777772839, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 110, training loss: 0.0831 , running loss:0.09712958578020334 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Validation loss : 0.0799317636641494 and metrics(micro,macro,acc) :(0.895163055373167, 0.9409984211199691, 0.8989010989010989, 0.8951630553726669, 0.1051954732510288)\n",
      "Epoch : 0 ,Iteration : 111, training loss: 0.1382 , running loss:0.09936465937644243 (0.75, 0.859375, 0.75, 0.7499999999995, 0.09523809523809523)\n",
      "Epoch : 0 ,Iteration : 112, training loss: 0.0374 , running loss:0.0989821346476674 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 113, training loss: 0.1345 , running loss:0.09740823153406382 (0.75, 0.859375, 0.75, 0.7499999999995, 0.09523809523809523)\n",
      "Epoch : 0 ,Iteration : 114, training loss: 0.1409 , running loss:0.09987503048032523 (0.75, 0.859375, 0.75, 0.7499999999995, 0.09523809523809523)\n",
      "Epoch : 0 ,Iteration : 115, training loss: 0.0369 , running loss:0.0994286123663187 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 116, training loss: 0.0372 , running loss:0.09127389229834079 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 117, training loss: 0.0361 , running loss:0.08648847229778767 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 118, training loss: 0.0356 , running loss:0.08609710074961185 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 119, training loss: 0.0358 , running loss:0.08327586594969034 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 120, training loss: 0.0839 , running loss:0.08266459312289953 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Validation loss : 0.07772196543713411 and metrics(micro,macro,acc) :(0.895163055373167, 0.9409984211199691, 0.8989010989010989, 0.8951630553726669, 0.1051954732510288)\n",
      "Epoch : 0 ,Iteration : 121, training loss: 0.0903 , running loss:0.08505813386291265 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 122, training loss: 0.0841 , running loss:0.08725709225982428 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 123, training loss: 0.1338 , running loss:0.08923690374940633 (0.75, 0.859375, 0.75, 0.7499999999995, 0.09523809523809523)\n",
      "Epoch : 0 ,Iteration : 124, training loss: 0.1432 , running loss:0.08709453847259283 (0.75, 0.859375, 0.75, 0.7499999999995, 0.09523809523809523)\n",
      "Epoch : 0 ,Iteration : 125, training loss: 0.0810 , running loss:0.08926226440817117 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 126, training loss: 0.0338 , running loss:0.08408976327627897 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 127, training loss: 0.0330 , running loss:0.08127093221992254 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 128, training loss: 0.0315 , running loss:0.08086476847529411 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 129, training loss: 0.0322 , running loss:0.07311809808015823 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 130, training loss: 0.0312 , running loss:0.07052709367126227 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Validation loss : 0.07554157113558367 and metrics(micro,macro,acc) :(0.895163055373167, 0.9409984211199691, 0.8989010989010989, 0.8951630553726669, 0.1051954732510288)\n",
      "Epoch : 0 ,Iteration : 131, training loss: 0.1295 , running loss:0.07009241711348295 (0.823529411764706, 0.8999536822603057, 0.875, 0.8235294117642077, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 132, training loss: 0.0851 , running loss:0.07247877698391676 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 133, training loss: 0.0858 , running loss:0.07004537675529718 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 134, training loss: 0.0900 , running loss:0.06750343535095453 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 135, training loss: 0.0875 , running loss:0.07003241200000047 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 136, training loss: 0.0287 , running loss:0.06960341585800052 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 137, training loss: 0.0884 , running loss:0.07222010036930442 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 138, training loss: 0.0287 , running loss:0.07187452325597406 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 139, training loss: 0.0781 , running loss:0.07398875122889877 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 140, training loss: 0.1903 , running loss:0.07930706283077597 (0.7058823529411765, 0.8332561371005095, 0.75, 0.7058823529406782, 0.09523809523809523)\n",
      "Validation loss : 0.07437846352133834 and metrics(micro,macro,acc) :(0.895163055373167, 0.9409984211199691, 0.8989010989010989, 0.8951630553726669, 0.1051954732510288)\n",
      "Epoch : 0 ,Iteration : 141, training loss: 0.1815 , running loss:0.08386559439823031 (0.7058823529411765, 0.8332561371005095, 0.75, 0.7058823529406782, 0.09523809523809523)\n",
      "Epoch : 0 ,Iteration : 142, training loss: 0.0841 , running loss:0.08386525576934219 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 143, training loss: 0.0282 , running loss:0.07858534380793572 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 144, training loss: 0.0303 , running loss:0.07294227406382561 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 145, training loss: 0.0286 , running loss:0.07032211050391197 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 146, training loss: 0.0859 , running loss:0.07292879186570644 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 147, training loss: 0.0767 , running loss:0.07511707097291946 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 148, training loss: 0.1472 , running loss:0.08090265560895205 (0.75, 0.859375, 0.75, 0.7499999999995, 0.09523809523809523)\n",
      "Epoch : 0 ,Iteration : 149, training loss: 0.0889 , running loss:0.08373706210404634 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 150, training loss: 0.0283 , running loss:0.08358986210078001 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Validation loss : 0.07412582897956957 and metrics(micro,macro,acc) :(0.895163055373167, 0.9409984211199691, 0.8989010989010989, 0.8951630553726669, 0.1051954732510288)\n",
      "Epoch : 0 ,Iteration : 151, training loss: 0.0260 , running loss:0.07841697223484516 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 152, training loss: 0.1858 , running loss:0.08344868347048759 (0.625, 0.7890625, 0.625, 0.6249999999995, 0.08547008547008547)\n",
      "Epoch : 0 ,Iteration : 153, training loss: 0.0281 , running loss:0.08056493224576115 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 154, training loss: 0.0269 , running loss:0.0774078312329948 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 155, training loss: 0.0825 , running loss:0.07715919939801097 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 ,Iteration : 156, training loss: 0.0822 , running loss:0.079834402538836 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 157, training loss: 0.0772 , running loss:0.07927316445857287 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 158, training loss: 0.0876 , running loss:0.08222005628049374 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 159, training loss: 0.0265 , running loss:0.07964166663587094 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 160, training loss: 0.0265 , running loss:0.07145281489938497 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Validation loss : 0.07309549920783753 and metrics(micro,macro,acc) :(0.895163055373167, 0.9409984211199691, 0.8989010989010989, 0.8951630553726669, 0.1051954732510288)\n",
      "Epoch : 0 ,Iteration : 161, training loss: 0.0250 , running loss:0.06362899634987115 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 162, training loss: 0.0250 , running loss:0.06067530447617173 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 163, training loss: 0.0239 , running loss:0.0604589874856174 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 164, training loss: 0.0239 , running loss:0.06013544695451856 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 165, training loss: 0.0829 , running loss:0.06285484367981553 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 166, training loss: 0.0239 , running loss:0.059755951073020695 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 167, training loss: 0.0235 , running loss:0.05709616960957646 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 168, training loss: 0.0231 , running loss:0.050890131201595065 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 169, training loss: 0.0866 , running loss:0.050774251203984024 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 170, training loss: 0.0796 , running loss:0.053339238930493596 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Validation loss : 0.07352545707110773 and metrics(micro,macro,acc) :(0.895163055373167, 0.9409984211199691, 0.8989010989010989, 0.8951630553726669, 0.1051954732510288)\n",
      "Epoch : 0 ,Iteration : 171, training loss: 0.0807 , running loss:0.056070263218134644 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 172, training loss: 0.2055 , running loss:0.05705795167014003 (0.7058823529411765, 0.8332561371005095, 0.75, 0.7058823529406782, 0.09523809523809523)\n",
      "Epoch : 0 ,Iteration : 173, training loss: 0.0803 , running loss:0.05966633874922991 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 174, training loss: 0.1433 , running loss:0.06548628397285938 (0.823529411764706, 0.8999536822603057, 0.875, 0.8235294117642077, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 175, training loss: 0.0764 , running loss:0.06518039554357528 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 176, training loss: 0.1453 , running loss:0.06833692118525506 (0.75, 0.859375, 0.75, 0.7499999999995, 0.09523809523809523)\n",
      "Epoch : 0 ,Iteration : 177, training loss: 0.1975 , running loss:0.0743497896939516 (0.625, 0.7890625, 0.625, 0.6249999999995, 0.08547008547008547)\n",
      "Epoch : 0 ,Iteration : 178, training loss: 0.0246 , running loss:0.07119716983288527 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 179, training loss: 0.0903 , running loss:0.07438937034457922 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 180, training loss: 0.1325 , running loss:0.07968997173011302 (0.75, 0.859375, 0.75, 0.7499999999995, 0.09523809523809523)\n",
      "Validation loss : 0.07477904713075412 and metrics(micro,macro,acc) :(0.895163055373167, 0.9409984211199691, 0.8989010989010989, 0.8951630553726669, 0.1051954732510288)\n",
      "Epoch : 0 ,Iteration : 181, training loss: 0.0273 , running loss:0.0798040246590972 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 182, training loss: 0.0765 , running loss:0.08238077005371451 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 183, training loss: 0.0265 , running loss:0.08250992940738797 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 184, training loss: 0.0266 , running loss:0.08264679871499539 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 185, training loss: 0.0242 , running loss:0.07970853988081217 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 186, training loss: 0.1463 , running loss:0.08582967482507228 (0.75, 0.859375, 0.75, 0.7499999999995, 0.09523809523809523)\n",
      "Epoch : 0 ,Iteration : 187, training loss: 0.0795 , running loss:0.0886281868442893 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 188, training loss: 0.0218 , running loss:0.08856255058199167 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 189, training loss: 0.0215 , running loss:0.08531000884249806 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 190, training loss: 0.0209 , running loss:0.08237563883885742 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Validation loss : 0.07218840291494863 and metrics(micro,macro,acc) :(0.895163055373167, 0.9409984211199691, 0.8989010989010989, 0.8951630553726669, 0.1051954732510288)\n",
      "Epoch : 0 ,Iteration : 191, training loss: 0.1426 , running loss:0.08547094715759158 (0.75, 0.859375, 0.75, 0.7499999999995, 0.09523809523809523)\n",
      "Epoch : 0 ,Iteration : 192, training loss: 0.1448 , running loss:0.08243621392175556 (0.75, 0.859375, 0.75, 0.7499999999995, 0.09523809523809523)\n",
      "Epoch : 0 ,Iteration : 193, training loss: 0.1410 , running loss:0.0854705291800201 (0.75, 0.859375, 0.75, 0.7499999999995, 0.09523809523809523)\n",
      "Epoch : 0 ,Iteration : 194, training loss: 0.0236 , running loss:0.07948433868587017 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 195, training loss: 0.0240 , running loss:0.07686394397169352 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 196, training loss: 0.0238 , running loss:0.07078899294137955 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 197, training loss: 0.0243 , running loss:0.06212982628494501 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 198, training loss: 0.0817 , running loss:0.0649843592196703 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 199, training loss: 0.0226 , running loss:0.061594702582806346 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 200, training loss: 0.0832 , running loss:0.05912818973883986 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Validation loss : 0.07267097619672616 and metrics(micro,macro,acc) :(0.895163055373167, 0.9409984211199691, 0.8989010989010989, 0.8951630553726669, 0.1051954732510288)\n",
      "Epoch : 0 ,Iteration : 201, training loss: 0.0791 , running loss:0.06171544352546334 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 202, training loss: 0.0779 , running loss:0.061783085484057663 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 203, training loss: 0.0198 , running loss:0.06145187858492136 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 204, training loss: 0.0192 , running loss:0.06108022378757596 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 205, training loss: 0.0195 , running loss:0.06084635928273201 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 206, training loss: 0.0194 , running loss:0.05450148656964302 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 207, training loss: 0.0818 , running loss:0.05461802072823048 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 ,Iteration : 208, training loss: 0.0834 , running loss:0.05770089123398066 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 209, training loss: 0.0911 , running loss:0.06117957672104239 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 210, training loss: 0.0195 , running loss:0.06111033335328102 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Validation loss : 0.07193113210562029 and metrics(micro,macro,acc) :(0.895163055373167, 0.9409984211199691, 0.8989010989010989, 0.8951630553726669, 0.1051954732510288)\n",
      "Epoch : 0 ,Iteration : 211, training loss: 0.1395 , running loss:0.06095629334449768 (0.823529411764706, 0.8999536822603057, 0.875, 0.8235294117642077, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 212, training loss: 0.0772 , running loss:0.0575767207890749 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 213, training loss: 0.3740 , running loss:0.06922699622809887 (0.35294117647058826, 0.6331635016211209, 0.375, 0.35294117647009, 0.0606060606060606)\n",
      "Epoch : 0 ,Iteration : 214, training loss: 0.0197 , running loss:0.0690355036407709 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 215, training loss: 0.1403 , running loss:0.07484946977347136 (0.75, 0.859375, 0.75, 0.7499999999995, 0.09523809523809523)\n",
      "Epoch : 0 ,Iteration : 216, training loss: 0.2115 , running loss:0.08423343077301979 (0.7058823529411765, 0.8332561371005095, 0.75, 0.7058823529406782, 0.09523809523809523)\n",
      "Epoch : 0 ,Iteration : 217, training loss: 0.0228 , running loss:0.08415829502046109 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 218, training loss: 0.0810 , running loss:0.08412570171058179 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 219, training loss: 0.0241 , running loss:0.08420252529904246 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 220, training loss: 0.0238 , running loss:0.08123410837724805 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Validation loss : 0.07207437534734869 and metrics(micro,macro,acc) :(0.895163055373167, 0.9409984211199691, 0.8989010989010989, 0.8951630553726669, 0.1051954732510288)\n",
      "Epoch : 0 ,Iteration : 221, training loss: 0.0811 , running loss:0.08133346373215318 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 222, training loss: 0.1364 , running loss:0.0842563428916037 (0.75, 0.859375, 0.75, 0.7499999999995, 0.09523809523809523)\n",
      "Epoch : 0 ,Iteration : 223, training loss: 0.1933 , running loss:0.09292881293222308 (0.7058823529411765, 0.8332561371005095, 0.75, 0.7058823529406782, 0.09523809523809523)\n",
      "Epoch : 0 ,Iteration : 224, training loss: 0.0756 , running loss:0.09575099861249328 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 225, training loss: 0.0200 , running loss:0.09577529598027468 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 226, training loss: 0.1544 , running loss:0.1025226542726159 (0.75, 0.859375, 0.75, 0.7499999999995, 0.09523809523809523)\n",
      "Epoch : 0 ,Iteration : 227, training loss: 0.0203 , running loss:0.09944410985335708 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 228, training loss: 0.0729 , running loss:0.09891867404803634 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 229, training loss: 0.1372 , running loss:0.10122146336361766 (0.75, 0.859375, 0.75, 0.7499999999995, 0.09523809523809523)\n",
      "Epoch : 0 ,Iteration : 230, training loss: 0.0209 , running loss:0.10128877442330123 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Validation loss : 0.07224587211221979 and metrics(micro,macro,acc) :(0.895163055373167, 0.9409984211199691, 0.8989010989010989, 0.8951630553726669, 0.1051954732510288)\n",
      "Epoch : 0 ,Iteration : 231, training loss: 0.1410 , running loss:0.1013653887435794 (0.75, 0.859375, 0.75, 0.7499999999995, 0.09523809523809523)\n",
      "Epoch : 0 ,Iteration : 232, training loss: 0.0200 , running loss:0.0985054318793118 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 233, training loss: 0.0806 , running loss:0.0838359166868031 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 234, training loss: 0.0916 , running loss:0.08742791265249253 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 235, training loss: 0.0206 , running loss:0.08144457936286927 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 236, training loss: 0.2540 , running loss:0.08357105627655984 (0.5, 0.71875, 0.5, 0.49999999999949996, 0.07407407407407407)\n",
      "Epoch : 0 ,Iteration : 237, training loss: 0.0755 , running loss:0.08620885964483023 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 238, training loss: 0.0213 , running loss:0.08322556298226118 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 239, training loss: 0.0216 , running loss:0.08310303147882223 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 240, training loss: 0.0761 , running loss:0.08571999333798885 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Validation loss : 0.07151529510554515 and metrics(micro,macro,acc) :(0.895163055373167, 0.9409984211199691, 0.8989010989010989, 0.8951630553726669, 0.1051954732510288)\n",
      "Epoch : 0 ,Iteration : 241, training loss: 0.0843 , running loss:0.08588319234549999 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 242, training loss: 0.0204 , running loss:0.08008336033672095 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 243, training loss: 0.1345 , running loss:0.07714382316917182 (0.75, 0.859375, 0.75, 0.7499999999995, 0.09523809523809523)\n",
      "Epoch : 0 ,Iteration : 244, training loss: 0.0195 , running loss:0.07433983590453863 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 245, training loss: 0.1398 , running loss:0.08033215533941984 (0.75, 0.859375, 0.75, 0.7499999999995, 0.09523809523809523)\n",
      "Epoch : 0 ,Iteration : 246, training loss: 0.0192 , running loss:0.07357337716966868 (1.0, 1.0, 1.0, 0.9999999999995, 0.1111111111111111)\n",
      "Epoch : 0 ,Iteration : 247, training loss: 0.0817 , running loss:0.07664529131725431 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 248, training loss: 0.2488 , running loss:0.08543808767572045 (0.5882352941176471, 0.7665585919407133, 0.625, 0.5882352941171487, 0.08547008547008547)\n",
      "Epoch : 0 ,Iteration : 249, training loss: 0.0801 , running loss:0.08258479656651616 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n",
      "Epoch : 0 ,Iteration : 250, training loss: 0.0834 , running loss:0.08571163704618812 (0.875, 0.9296875, 0.875, 0.8749999999995, 0.1037037037037037)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6099/168898160.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m \u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_6099/168898160.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(base_model, train_dataloader, optimizer, loss_function)\u001b[0m\n\u001b[1;32m    129\u001b[0m                         \u001b[0;31m# emptying memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                         \u001b[0;32mdel\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_input_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m                         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "base_model.to(device)\n",
    "def compute_f1_score(true_labels, predicted_labels):\n",
    "    num_labels = true_labels.shape[1]\n",
    "    f1_scores = []\n",
    "\n",
    "    for label_idx in range(num_labels):\n",
    "        true_positives = np.sum(np.logical_and(true_labels[:, label_idx], predicted_labels[:, label_idx]))\n",
    "        false_positives = np.sum(np.logical_and(np.logical_not(true_labels[:, label_idx]), predicted_labels[:, label_idx]))\n",
    "        false_negatives = np.sum(np.logical_and(true_labels[:, label_idx], np.logical_not(predicted_labels[:, label_idx])))\n",
    "\n",
    "        precision = true_positives / (true_positives + false_positives + 1e-16)\n",
    "        recall = true_positives / (true_positives + false_negatives + 1e-16)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall + 1e-16)\n",
    "\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    macro_f1_score = np.mean(f1_scores)\n",
    "\n",
    "    return macro_f1_score\n",
    "def gpt_imp(predicted_labels,true_labels):\n",
    "    # Calculate true positives, false positives, and false negatives\n",
    "    true_positives = torch.logical_and(predicted_labels, true_labels).sum().item()\n",
    "    false_positives = (predicted_labels.logical_not() & true_labels).sum().item()\n",
    "    false_negatives = (predicted_labels & true_labels.logical_not()).sum().item()\n",
    "\n",
    "    # Calculate precision, recall, and micro F1 score\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "    micro_f1_score = 2 * (precision * recall) / (precision + recall + 0.000000000001)\n",
    "    return micro_f1_score\n",
    "    \n",
    "def find_metrics1(targets,prediction):\n",
    "    final_pred = ((torch.sigmoid(prediction) >= 0.5) * 1.0)\n",
    "    #final_pred = prediction\n",
    "    \n",
    "    append_out = torch.cat((final_pred,((torch.sum(final_pred,dim=1) < 1.0)  * 1.0).unsqueeze(1)),dim=1)\n",
    "    append_tar = torch.cat((targets,((torch.sum(targets,dim=1) < 1.0)  * 1.0).unsqueeze(1)),dim=1)\n",
    "\n",
    "    np_tar = append_tar.cpu().detach().numpy()\n",
    "    np_pred = append_out.cpu().detach().numpy()\n",
    "    \n",
    "    avg_f1_mic = f1_score(np_tar, np_pred, average='micro',zero_division=0)\n",
    "    avg_f1_mac = f1_score(np_tar.flatten(), np_pred.flatten(), average='macro',zero_division=0)\n",
    "    avg_acc = accuracy_score(np_tar, np_pred)\n",
    "    waise_hi = gpt_imp(append_tar.to(torch.int64),append_out.to(torch.int64))\n",
    "    waise_hi2 = compute_f1_score(np_tar,np_pred)\n",
    "    del np_tar\n",
    "    del np_pred\n",
    "    del final_pred\n",
    "    \n",
    "    return avg_f1_mic, avg_f1_mac, avg_acc, waise_hi,waise_hi2\n",
    "\n",
    "\n",
    "def train(base_model,train_dataloader,optimizer,loss_function):\n",
    "    # Training loop\n",
    "    \n",
    "    max_mac = 0\n",
    "    max_mic = 0\n",
    "    acc_step = 2\n",
    "    num_epochs = 20\n",
    "    valid_interval = 10  # Perform validation and save model every 10 iterations\n",
    "    iteration = 0\n",
    "    \n",
    "    stop_criterion = 2000000\n",
    "\n",
    "    running_loss = []\n",
    "    for epoch in range(num_epochs):\n",
    "        base_model.train()  # Set the model to training mode\n",
    "        for curr_batch in train_dataloader:\n",
    "            \n",
    "            if iteration > stop_criterion:\n",
    "                break\n",
    "            \n",
    "            input_ids = curr_batch['input_ids'].to(device)\n",
    "            attention_mask = curr_batch['attention_mask'].to(device)\n",
    "            targets = curr_batch['multi_label'].to(device)\n",
    "\n",
    "\n",
    "            outputs = base_model(input_ids,attention_mask)\n",
    "            loss = loss_function(outputs.to(device), targets)\n",
    "            \n",
    "            if iteration % acc_step == 0:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            #print (iteration)\n",
    "            running_loss.append(loss.item())\n",
    "            if len(running_loss) > 20:\n",
    "                running_loss.pop(0)\n",
    "            #print (f\"Epoch : {epoch} ,Iteration : {iteration}, training loss: {loss:.4f} , running loss:{sum(running_loss)/len(running_loss)}\")            \n",
    "            print (f\"Epoch : {epoch} ,Iteration : {iteration}, training loss: {loss:.4f} , running loss:{sum(running_loss)/len(running_loss)}\",find_metrics1(targets,outputs))\n",
    "            \n",
    "            # freeing up excess memory\n",
    "            del loss, outputs\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            # Validation and model saving\n",
    "            if iteration % valid_interval == 0:\n",
    "                base_model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    total_loss = []\n",
    "                    \n",
    "                    full_metric_tar = []\n",
    "                    full_metric_out = []\n",
    "                    \n",
    "                    for val_batch in val_dataloader:\n",
    "                        val_input_ids = val_batch['input_ids'].to(device)\n",
    "                        val_attention_mask = val_batch['attention_mask'].to(device)\n",
    "                        val_targets = val_batch['multi_label'].to(device)\n",
    "\n",
    "\n",
    "                        outputs = base_model(val_input_ids,val_attention_mask)\n",
    "                        loss = loss_function(outputs.to(device), val_targets)                        \n",
    "                        \n",
    "                        total_loss.append(loss.item())\n",
    "                        if full_metric_out == []:\n",
    "                            full_metric_out = outputs.detach().clone()\n",
    "                            full_metric_tar = val_targets.detach().clone()\n",
    "                        else:\n",
    "                            full_metric_out = torch.cat((full_metric_out,outputs.detach()),dim=0)\n",
    "                            full_metric_tar = torch.cat((full_metric_tar,val_targets.detach()),dim=0)\n",
    "\n",
    "                        # emptying memory\n",
    "                        del loss, outputs, val_targets, val_input_ids\n",
    "                        gc.collect()\n",
    "                        torch.cuda.empty_cache()\n",
    "                        \n",
    "                    avg_loss = sum(total_loss)/len(total_loss)\n",
    "                    val_out_met = find_metrics1(full_metric_tar,full_metric_out)\n",
    "                    print (f\"Validation loss : {sum(total_loss)/len(total_loss)} and metrics(micro,macro,acc) :{val_out_met}\")\n",
    "                    if val_out_met[1] > max_mac :\n",
    "                        torch.save(base_model.state_dict(),f\"model_trained/model_macro_{iteration}.pth\")\n",
    "                        max_mac = val_out_met[1]\n",
    "                    if val_out_met[0] > max_mic:\n",
    "                        torch.save(base_model.state_dict(),f\"model_trained/model_micro_{iteration}.pth\")\n",
    "                        max_mic = val_out_met[0]\n",
    "\n",
    "                    del total_loss\n",
    "\n",
    "                base_model.train()  # Set the model back to training mode\n",
    "            \n",
    "            iteration += 1\n",
    "    return base_model, train_dataloader, optimizer, loss_function\n",
    "\n",
    "base_model, train_dataloader, optimizer, loss_function = train(base_model,train_dataloader,optimizer,loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a758e8a",
   "metadata": {},
   "source": [
    "### Find out memory leaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8ead40ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7efb7a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "427178\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([30522, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([2, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([8])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([8, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([8, 768])\n",
      "<class 'torch.Tensor'> torch.Size([8, 768])\n",
      "<class 'torch.Tensor'> torch.Size([8, 768])\n",
      "<class 'torch.Tensor'> torch.Size([8])\n",
      "<class 'torch.Tensor'> torch.Size([8])\n",
      "<class 'torch.Tensor'> torch.Size([8])\n",
      "<class 'torch.Tensor'> torch.Size([1, 512])\n",
      "<class 'torch.Tensor'> torch.Size([1, 512])\n",
      "<class 'torch.Tensor'> torch.Size([30522, 768])\n",
      "<class 'torch.Tensor'> torch.Size([30522, 768])\n",
      "<class 'torch.Tensor'> torch.Size([30522, 768])\n",
      "<class 'torch.Tensor'> torch.Size([512, 768])\n",
      "<class 'torch.Tensor'> torch.Size([512, 768])\n",
      "<class 'torch.Tensor'> torch.Size([512, 768])\n",
      "<class 'torch.Tensor'> torch.Size([2, 768])\n",
      "<class 'torch.Tensor'> torch.Size([2, 768])\n",
      "<class 'torch.Tensor'> torch.Size([2, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([512])\n",
      "<class 'torch.Tensor'> torch.Size([1, 512])\n",
      "<class 'torch.Tensor'> torch.Size([30522, 768])\n",
      "<class 'torch.Tensor'> torch.Size([512, 768])\n",
      "<class 'torch.Tensor'> torch.Size([2, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768, 768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768])\n",
      "<class 'torch.Tensor'> torch.Size([3072])\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.Tensor'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([8, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([8])\n",
      "<class 'torch.Tensor'> torch.Size([1, 512])\n",
      "<class 'torch.Tensor'> torch.Size([1, 512])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([30522, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([2, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anas/anaconda3/envs/legal_env/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py:262: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# prints currently alive Tensors and Variables\n",
    "import torch\n",
    "import gc\n",
    "print (len(gc.get_objects()))\n",
    "for obj in gc.get_objects():\n",
    "    try:\n",
    "        if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
    "            print(type(obj), obj.size())\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99e95409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local variables:\n",
      "__name__: 57 bytes\n",
      "__doc__: 113 bytes\n",
      "__package__: 16 bytes\n",
      "__loader__: 16 bytes\n",
      "__spec__: 16 bytes\n",
      "__builtin__: 72 bytes\n",
      "__builtins__: 72 bytes\n",
      "_ih: 312 bytes\n",
      "_oh: 232 bytes\n",
      "_dh: 64 bytes\n",
      "In: 312 bytes\n",
      "Out: 232 bytes\n",
      "get_ipython: 64 bytes\n",
      "exit: 48 bytes\n",
      "quit: 48 bytes\n",
      "_: 49 bytes\n",
      "__: 49 bytes\n",
      "___: 49 bytes\n",
      "_i: 385 bytes\n",
      "_ii: 341 bytes\n",
      "_iii: 99 bytes\n",
      "_i1: 1634 bytes\n",
      "np: 72 bytes\n",
      "torch: 72 bytes\n",
      "nn: 72 bytes\n",
      "optim: 72 bytes\n",
      "Dataset: 1064 bytes\n",
      "DataLoader: 1472 bytes\n",
      "BertTokenizer: 2008 bytes\n",
      "dts: 72 bytes\n",
      "pd: 72 bytes\n",
      "sns: 72 bytes\n",
      "plt: 72 bytes\n",
      "nltk: 72 bytes\n",
      "re: 72 bytes\n",
      "gc: 72 bytes\n",
      "stopwords: 48 bytes\n",
      "CountVectorizer: 1064 bytes\n",
      "TfidfVectorizer: 1064 bytes\n",
      "WordCloud: 1064 bytes\n",
      "STOPWORDS: 8408 bytes\n",
      "SnowballStemmer: 1064 bytes\n",
      "train_test_split: 136 bytes\n",
      "TfidfTransformer: 1064 bytes\n",
      "MultinomialNB: 1064 bytes\n",
      "OneVsRestClassifier: 1064 bytes\n",
      "LinearSVC: 1064 bytes\n",
      "LogisticRegression: 1064 bytes\n",
      "Pipeline: 1064 bytes\n",
      "MultiLabelBinarizer: 1064 bytes\n",
      "BinaryRelevance: 1064 bytes\n",
      "ClassifierChain: 1064 bytes\n",
      "TomekLinks: 1064 bytes\n",
      "RandomUnderSampler: 1064 bytes\n",
      "BertModel: 1472 bytes\n",
      "f1_score: 136 bytes\n",
      "hamming_loss: 136 bytes\n",
      "accuracy_score: 136 bytes\n",
      "_i2: 100 bytes\n",
      "dataset: 248 bytes\n",
      "_i3: 267 bytes\n",
      "train_dataset: 1606340 bytes\n",
      "val_dataset: 681180 bytes\n",
      "test_dataset: 474769 bytes\n",
      "stop_words: 1488 bytes\n",
      "_i4: 5411 bytes\n",
      "definitions: 360 bytes\n",
      "entailment_con: 64 bytes\n",
      "_i5: 805 bytes\n",
      "BERTClassifier: 1472 bytes\n",
      "learning_rate: 24 bytes\n",
      "num_classes: 28 bytes\n",
      "base_model: 48 bytes\n",
      "loss_function: 48 bytes\n",
      "optimizer: 48 bytes\n",
      "_i6: 1494 bytes\n",
      "CustomDataset: 1064 bytes\n",
      "tokenizer: 48 bytes\n",
      "batch_size: 28 bytes\n",
      "train_custom: 48 bytes\n",
      "train_dataloader: 48 bytes\n",
      "valid_custom: 48 bytes\n",
      "valid_dataloader: 48 bytes\n",
      "_i7: 1872 bytes\n",
      "device: 24 bytes\n",
      "train: 136 bytes\n",
      "_i8: 99 bytes\n",
      "_i9: 783 bytes\n",
      "_i10: 1494 bytes\n",
      "_i11: 1872 bytes\n",
      "_i12: 1516 bytes\n",
      "_i13: 1872 bytes\n",
      "_i14: 765 bytes\n",
      "_i15: 1516 bytes\n",
      "_i16: 1872 bytes\n",
      "_i17: 1494 bytes\n",
      "_i18: 1872 bytes\n",
      "_i19: 341 bytes\n",
      "obj: 232 bytes\n",
      "_i20: 1876 bytes\n",
      "_i21: 99 bytes\n",
      "_i22: 341 bytes\n",
      "_i23: 385 bytes\n",
      "sys: 72 bytes\n",
      "name: 52 bytes\n",
      "value: 52 bytes\n",
      "_i24: 385 bytes\n",
      "Global variables:\n",
      "__name__: 57 bytes\n",
      "__doc__: 113 bytes\n",
      "__package__: 16 bytes\n",
      "__loader__: 16 bytes\n",
      "__spec__: 16 bytes\n",
      "__builtin__: 72 bytes\n",
      "__builtins__: 72 bytes\n",
      "_ih: 312 bytes\n",
      "_oh: 232 bytes\n",
      "_dh: 64 bytes\n",
      "In: 312 bytes\n",
      "Out: 232 bytes\n",
      "get_ipython: 64 bytes\n",
      "exit: 48 bytes\n",
      "quit: 48 bytes\n",
      "_: 49 bytes\n",
      "__: 49 bytes\n",
      "___: 49 bytes\n",
      "_i: 385 bytes\n",
      "_ii: 341 bytes\n",
      "_iii: 99 bytes\n",
      "_i1: 1634 bytes\n",
      "np: 72 bytes\n",
      "torch: 72 bytes\n",
      "nn: 72 bytes\n",
      "optim: 72 bytes\n",
      "Dataset: 1064 bytes\n",
      "DataLoader: 1472 bytes\n",
      "BertTokenizer: 2008 bytes\n",
      "dts: 72 bytes\n",
      "pd: 72 bytes\n",
      "sns: 72 bytes\n",
      "plt: 72 bytes\n",
      "nltk: 72 bytes\n",
      "re: 72 bytes\n",
      "gc: 72 bytes\n",
      "stopwords: 48 bytes\n",
      "CountVectorizer: 1064 bytes\n",
      "TfidfVectorizer: 1064 bytes\n",
      "WordCloud: 1064 bytes\n",
      "STOPWORDS: 8408 bytes\n",
      "SnowballStemmer: 1064 bytes\n",
      "train_test_split: 136 bytes\n",
      "TfidfTransformer: 1064 bytes\n",
      "MultinomialNB: 1064 bytes\n",
      "OneVsRestClassifier: 1064 bytes\n",
      "LinearSVC: 1064 bytes\n",
      "LogisticRegression: 1064 bytes\n",
      "Pipeline: 1064 bytes\n",
      "MultiLabelBinarizer: 1064 bytes\n",
      "BinaryRelevance: 1064 bytes\n",
      "ClassifierChain: 1064 bytes\n",
      "TomekLinks: 1064 bytes\n",
      "RandomUnderSampler: 1064 bytes\n",
      "BertModel: 1472 bytes\n",
      "f1_score: 136 bytes\n",
      "hamming_loss: 136 bytes\n",
      "accuracy_score: 136 bytes\n",
      "_i2: 100 bytes\n",
      "dataset: 248 bytes\n",
      "_i3: 267 bytes\n",
      "train_dataset: 1606340 bytes\n",
      "val_dataset: 681180 bytes\n",
      "test_dataset: 474769 bytes\n",
      "stop_words: 1488 bytes\n",
      "_i4: 5411 bytes\n",
      "definitions: 360 bytes\n",
      "entailment_con: 64 bytes\n",
      "_i5: 805 bytes\n",
      "BERTClassifier: 1472 bytes\n",
      "learning_rate: 24 bytes\n",
      "num_classes: 28 bytes\n",
      "base_model: 48 bytes\n",
      "loss_function: 48 bytes\n",
      "optimizer: 48 bytes\n",
      "_i6: 1494 bytes\n",
      "CustomDataset: 1064 bytes\n",
      "tokenizer: 48 bytes\n",
      "batch_size: 28 bytes\n",
      "train_custom: 48 bytes\n",
      "train_dataloader: 48 bytes\n",
      "valid_custom: 48 bytes\n",
      "valid_dataloader: 48 bytes\n",
      "_i7: 1872 bytes\n",
      "device: 24 bytes\n",
      "train: 136 bytes\n",
      "_i8: 99 bytes\n",
      "_i9: 783 bytes\n",
      "_i10: 1494 bytes\n",
      "_i11: 1872 bytes\n",
      "_i12: 1516 bytes\n",
      "_i13: 1872 bytes\n",
      "_i14: 765 bytes\n",
      "_i15: 1516 bytes\n",
      "_i16: 1872 bytes\n",
      "_i17: 1494 bytes\n",
      "_i18: 1872 bytes\n",
      "_i19: 341 bytes\n",
      "obj: 232 bytes\n",
      "_i20: 1876 bytes\n",
      "_i21: 99 bytes\n",
      "_i22: 341 bytes\n",
      "_i23: 385 bytes\n",
      "sys: 72 bytes\n",
      "name: 52 bytes\n",
      "value: 52 bytes\n",
      "_i24: 385 bytes\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# Print local variable names with memory space\n",
    "print(\"Local variables:\")\n",
    "for name, value in locals().items():\n",
    "    print(f\"{name}: {sys.getsizeof(value)} bytes\")\n",
    "\n",
    "# Print global variable names with memory space\n",
    "print(\"Global variables:\")\n",
    "for name, value in globals().items():\n",
    "    print(f\"{name}: {sys.getsizeof(value)} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd7e867",
   "metadata": {},
   "source": [
    "### Balanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "330fbdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_it(curr):\n",
    "    return [curr]\n",
    "\n",
    "train_dataset['text_2d'] = train_dataset[\"text\"].apply(list_it)\n",
    "train_dataset['str_labels'] = train_dataset[\"labels\"].apply(str)\n",
    "\n",
    "rus = RandomUnderSampler(sampling_strategy='majority')\n",
    "X_train_resampled, y_train_resampled = rus.fit_resample(np.array(train_dataset[\"text_2d\"]).reshape(-1, 1),train_dataset['str_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6d12e162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delist_it(curr):\n",
    "    new_list = []\n",
    "    for i in curr:\n",
    "        new_list.append(i[0][0])\n",
    "    return new_list\n",
    "def str2list(curr):\n",
    "    if curr==\"[]\":\n",
    "        return []\n",
    "    else:\n",
    "        return [int(x) for x in curr[1:-1].split(',')]\n",
    "x_train_weight = {}\n",
    "x_train_weight[\"text\"] = delist_it(X_train_resampled)\n",
    "x_train_weight[\"labels\"] = y_train_resampled.apply(str2list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "cb973ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_custom_w = CustomDataset(x_train_weight, num_classes,tokenizer)\n",
    "train_dataloader_w = DataLoader(train_custom_w, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "032547cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 ,Iteration : 0, training loss: 0.7228 , running loss:0.7227567434310913 (0.53125, 0.23402777777777778, 0.0)\n",
      "Validation loss : 0.6665522667399624   ,acc :  0.016228070175438595  ,f1-micro :  0.764437134502924  ,f1-macro :  0.41703390420495645\n",
      "Epoch : 0 ,Iteration : 1, training loss: 0.6695 , running loss:0.696148693561554 (0.703125, 0.22499999999999998, 0.0)\n",
      "Epoch : 0 ,Iteration : 2, training loss: 0.5594 , running loss:0.6505704720815023 (0.796875, 0.3409090909090909, 0.125)\n",
      "Epoch : 0 ,Iteration : 3, training loss: 0.5836 , running loss:0.6338293254375458 (0.8125, 0.5056818181818181, 0.125)\n",
      "Epoch : 0 ,Iteration : 4, training loss: 0.5987 , running loss:0.6268131971359253 (0.78125, 0.425, 0.125)\n",
      "Epoch : 0 ,Iteration : 5, training loss: 0.5837 , running loss:0.6196288466453552 (0.8125, 0.6333333333333333, 0.25)\n",
      "Epoch : 0 ,Iteration : 6, training loss: 0.5572 , running loss:0.6107116256441388 (0.8125, 0.425, 0.25)\n",
      "Epoch : 0 ,Iteration : 7, training loss: 0.5589 , running loss:0.6042363345623016 (0.765625, 0.3181818181818182, 0.25)\n",
      "Epoch : 0 ,Iteration : 8, training loss: 0.5040 , running loss:0.5930991503927443 (0.828125, 0.7583333333333333, 0.25)\n",
      "Epoch : 0 ,Iteration : 9, training loss: 0.5618 , running loss:0.589965945482254 (0.734375, 0.25, 0.0)\n",
      "Epoch : 0 ,Iteration : 10, training loss: 0.5289 , running loss:0.5844146392562173 (0.78125, 0.4305555555555556, 0.125)\n",
      "Validation loss : 0.44426877446341934   ,acc :  0.03508771929824561  ,f1-micro :  0.86875  ,f1-macro :  0.7959531720715923\n",
      "Epoch : 0 ,Iteration : 11, training loss: 0.4819 , running loss:0.5758753071228663 (0.84375, 0.5681818181818181, 0.375)\n",
      "Epoch : 0 ,Iteration : 12, training loss: 0.4721 , running loss:0.56789136162171 (0.875, 0.5833333333333333, 0.375)\n",
      "Epoch : 0 ,Iteration : 13, training loss: 0.5131 , running loss:0.5639801898172924 (0.8125, 0.4375, 0.125)\n",
      "Epoch : 0 ,Iteration : 14, training loss: 0.4743 , running loss:0.5580031077067057 (0.875, 0.4583333333333333, 0.125)\n",
      "Epoch : 0 ,Iteration : 15, training loss: 0.4835 , running loss:0.553347036242485 (0.84375, 0.5625, 0.0)\n",
      "Epoch : 0 ,Iteration : 16, training loss: 0.4375 , running loss:0.5465308760895449 (0.875, 0.375, 0.0)\n",
      "Epoch : 0 ,Iteration : 17, training loss: 0.4232 , running loss:0.5396791746219 (0.875, 0.5, 0.0)\n",
      "Epoch : 0 ,Iteration : 18, training loss: 0.4203 , running loss:0.5333939806411141 (0.875, 0.375, 0.0)\n",
      "Epoch : 0 ,Iteration : 19, training loss: 0.4465 , running loss:0.529047779738903 (0.859375, 0.375, 0.0)\n",
      "Epoch : 0 ,Iteration : 20, training loss: 0.4430 , running loss:0.5150609269738198 (0.875, 0.375, 0.0)\n",
      "Validation loss : 0.3328185340814423   ,acc :  0.8929824561403509  ,f1-micro :  0.9855811403508772  ,f1-macro :  0.8921052631578947\n",
      "Epoch : 0 ,Iteration : 21, training loss: 0.4085 , running loss:0.5020091503858566 (0.859375, 0.5, 0.0)\n",
      "Epoch : 0 ,Iteration : 22, training loss: 0.4423 , running loss:0.496154373884201 (0.828125, 0.5, 0.0)\n",
      "Epoch : 0 ,Iteration : 23, training loss: 0.4094 , running loss:0.48744494915008546 (0.859375, 0.5, 0.0)\n",
      "Epoch : 0 ,Iteration : 24, training loss: 0.4258 , running loss:0.47879658639431 (0.84375, 0.25, 0.0)\n",
      "Epoch : 0 ,Iteration : 25, training loss: 0.3861 , running loss:0.4689186066389084 (0.875, 0.5, 0.0)\n",
      "Epoch : 0 ,Iteration : 26, training loss: 0.4797 , running loss:0.4650442063808441 (0.859375, 0.375, 0.0)\n",
      "Epoch : 0 ,Iteration : 27, training loss: 0.3769 , running loss:0.45594397485256194 (0.890625, 0.4375, 0.125)\n",
      "Epoch : 0 ,Iteration : 28, training loss: 0.3852 , running loss:0.45000589191913604 (0.859375, 0.375, 0.0)\n",
      "Epoch : 0 ,Iteration : 29, training loss: 0.3910 , running loss:0.44146682769060136 (0.875, 0.125, 0.0)\n",
      "Epoch : 0 ,Iteration : 30, training loss: 0.3807 , running loss:0.4340549409389496 (0.859375, 0.5, 0.0)\n",
      "Validation loss : 0.26577516177244354   ,acc :  0.8978070175438596  ,f1-micro :  0.9861842105263158  ,f1-macro :  0.8969298245614035\n",
      "Epoch : 0 ,Iteration : 31, training loss: 0.3811 , running loss:0.4290143668651581 (0.875, 0.625, 0.125)\n",
      "Epoch : 0 ,Iteration : 32, training loss: 0.4049 , running loss:0.42565408200025556 (0.875, 0.25, 0.0)\n",
      "Epoch : 0 ,Iteration : 33, training loss: 0.3225 , running loss:0.4161200672388077 (0.890625, 0.625, 0.125)\n",
      "Epoch : 0 ,Iteration : 34, training loss: 0.3835 , running loss:0.4115790009498596 (0.84375, 0.375, 0.0)\n",
      "Epoch : 0 ,Iteration : 35, training loss: 0.4180 , running loss:0.40830221474170686 (0.859375, 0.375, 0.0)\n",
      "Epoch : 0 ,Iteration : 36, training loss: 0.3334 , running loss:0.4031008809804916 (0.875, 0.375, 0.0)\n",
      "Epoch : 0 ,Iteration : 37, training loss: 0.4075 , running loss:0.4023150116205215 (0.828125, 0.25, 0.0)\n",
      "Epoch : 0 ,Iteration : 38, training loss: 0.3670 , running loss:0.3996538072824478 (0.84375, 0.625, 0.0)\n",
      "Epoch : 0 ,Iteration : 39, training loss: 0.4001 , running loss:0.39733706712722777 (0.84375, 0.25, 0.0)\n",
      "Epoch : 0 ,Iteration : 40, training loss: 0.3075 , running loss:0.39055938422679903 (0.875, 0.625, 0.0)\n",
      "Validation loss : 0.2274557492712088   ,acc :  0.8991228070175439  ,f1-micro :  0.9863486842105263  ,f1-macro :  0.8973684210526316\n",
      "Epoch : 0 ,Iteration : 41, training loss: 0.4504 , running loss:0.3926540330052376 (0.859375, 0.25, 0.0)\n",
      "Epoch : 0 ,Iteration : 42, training loss: 0.3625 , running loss:0.3886616572737694 (0.84375, 0.375, 0.0)\n",
      "Epoch : 0 ,Iteration : 43, training loss: 0.3602 , running loss:0.3862014338374138 (0.875, 0.375, 0.0)\n",
      "Epoch : 0 ,Iteration : 44, training loss: 0.3423 , running loss:0.3820288136601448 (0.875, 0.375, 0.0)\n",
      "Epoch : 0 ,Iteration : 45, training loss: 0.3587 , running loss:0.38065786808729174 (0.875, 0.25, 0.0)\n",
      "Epoch : 0 ,Iteration : 46, training loss: 0.3949 , running loss:0.37641611546278 (0.859375, 0.125, 0.0)\n",
      "Epoch : 0 ,Iteration : 47, training loss: 0.3710 , running loss:0.3761199712753296 (0.828125, 0.375, 0.0)\n",
      "Epoch : 0 ,Iteration : 48, training loss: 0.3573 , running loss:0.3747253954410553 (0.859375, 0.375, 0.0)\n",
      "Epoch : 0 ,Iteration : 49, training loss: 0.3156 , running loss:0.3709559187293053 (0.859375, 0.5, 0.0)\n",
      "Epoch : 0 ,Iteration : 50, training loss: 0.2887 , running loss:0.36635940670967104 (0.90625, 0.6875, 0.25)\n",
      "Validation loss : 0.2153221103705858   ,acc :  0.9  ,f1-micro :  0.9864583333333333  ,f1-macro :  0.8967836257309942\n",
      "Epoch : 0 ,Iteration : 51, training loss: 0.3470 , running loss:0.364653417468071 (0.859375, 0.375, 0.0)\n",
      "Epoch : 0 ,Iteration : 52, training loss: 0.4139 , running loss:0.36510435342788694 (0.84375, 0.375, 0.0)\n",
      "Epoch : 0 ,Iteration : 53, training loss: 0.4097 , running loss:0.3694689080119133 (0.828125, 0.125, 0.0)\n",
      "Epoch : 0 ,Iteration : 54, training loss: 0.4195 , running loss:0.3712689861655235 (0.859375, 0.375, 0.0)\n",
      "Epoch : 0 ,Iteration : 55, training loss: 0.2803 , running loss:0.36438513100147246 (0.90625, 0.6, 0.25)\n",
      "Epoch : 0 ,Iteration : 56, training loss: 0.3545 , running loss:0.3654380068182945 (0.84375, 0.25, 0.0)\n",
      "Epoch : 0 ,Iteration : 57, training loss: 0.3228 , running loss:0.3612041980028152 (0.875, 0.375, 0.0)\n",
      "Epoch : 0 ,Iteration : 58, training loss: 0.3163 , running loss:0.35866607129573824 (0.84375, 0.5, 0.0)\n",
      "Epoch : 0 ,Iteration : 59, training loss: 0.2913 , running loss:0.3532264858484268 (0.90625, 0.6, 0.25)\n",
      "Epoch : 0 ,Iteration : 60, training loss: 0.3365 , running loss:0.35467880964279175 (0.859375, 0.25, 0.0)\n",
      "Validation loss : 0.19427156547705332   ,acc :  0.8847953216374269  ,f1-micro :  0.9845577485380116  ,f1-macro :  0.8874269005847953\n",
      "Epoch : 0 ,Iteration : 61, training loss: 0.3350 , running loss:0.3489090710878372 (0.875, 0.5, 0.0)\n",
      "Epoch : 0 ,Iteration : 62, training loss: 0.3509 , running loss:0.3483323141932487 (0.859375, 0.125, 0.0)\n",
      "Epoch : 0 ,Iteration : 63, training loss: 0.3184 , running loss:0.3462400421500206 (0.875, 0.3125, 0.125)\n",
      "Epoch : 0 ,Iteration : 64, training loss: 0.3217 , running loss:0.34520977586507795 (0.859375, 0.4375, 0.125)\n",
      "Epoch : 0 ,Iteration : 65, training loss: 0.2770 , running loss:0.3411242440342903 (0.890625, 0.675, 0.125)\n",
      "Epoch : 0 ,Iteration : 66, training loss: 0.2869 , running loss:0.33572306483983994 (0.90625, 0.5714285714285714, 0.25)\n",
      "Epoch : 0 ,Iteration : 67, training loss: 0.3420 , running loss:0.3342745780944824 (0.859375, 0.5, 0.0)\n",
      "Epoch : 0 ,Iteration : 68, training loss: 0.2989 , running loss:0.3313536524772644 (0.875, 0.4375, 0.125)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 ,Iteration : 69, training loss: 0.3168 , running loss:0.33141190111637114 (0.90625, 0.375, 0.25)\n",
      "Epoch : 0 ,Iteration : 70, training loss: 0.2569 , running loss:0.32981830537319184 (0.875, 0.6666666666666667, 0.125)\n",
      "Validation loss : 0.19155651388461128   ,acc :  0.8747076023391812  ,f1-micro :  0.9832419590643274  ,f1-macro :  0.8840643274853802\n",
      "Epoch : 0 ,Iteration : 71, training loss: 0.2903 , running loss:0.3269809141755104 (0.875, 0.4375, 0.125)\n",
      "Epoch : 0 ,Iteration : 72, training loss: 0.3663 , running loss:0.32460304349660873 (0.875, 0.375, 0.0)\n",
      "Epoch : 0 ,Iteration : 73, training loss: 0.3073 , running loss:0.3194793462753296 (0.875, 0.5625, 0.125)\n",
      "Epoch : 0 ,Iteration : 74, training loss: 0.3051 , running loss:0.31375869959592817 (0.875, 0.35, 0.25)\n",
      "Epoch : 0 ,Iteration : 75, training loss: 0.3889 , running loss:0.31918873339891435 (0.859375, 0.25, 0.0)\n",
      "Epoch : 0 ,Iteration : 76, training loss: 0.2957 , running loss:0.3162463799118996 (0.875, 0.375, 0.0)\n",
      "Epoch : 0 ,Iteration : 77, training loss: 0.3387 , running loss:0.31704258024692533 (0.875, 0.35, 0.25)\n",
      "Epoch : 0 ,Iteration : 78, training loss: 0.3852 , running loss:0.3204907447099686 (0.8571428571428571, 0.375, 0.0)\n",
      "Epoch : 1 ,Iteration : 79, training loss: 0.3246 , running loss:0.3221513956785202 (0.859375, 0.5, 0.125)\n",
      "Epoch : 1 ,Iteration : 80, training loss: 0.2758 , running loss:0.31911509931087495 (0.90625, 0.6625, 0.375)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6746/1623222666.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m \u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_dataloader_w\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_6746/1623222666.py\u001b[0m in \u001b[0;36mtrain_w\u001b[0;34m(base_model, train_dataloader, optimizer, loss_function)\u001b[0m\n\u001b[1;32m     71\u001b[0m                         \u001b[0;31m# emptying memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                         \u001b[0;32mdel\u001b[0m \u001b[0mval_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m                         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "base_model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "def train_w(base_model,train_dataloader,optimizer,loss_function):\n",
    "    # Training loop\n",
    "    num_epochs = 20\n",
    "    valid_interval = 10  # Perform validation and save model every 10 iterations\n",
    "    iteration = 0\n",
    "    acc_step = 2\n",
    "    stop_criterion = 2000000\n",
    "\n",
    "    running_loss = []\n",
    "    for epoch in range(num_epochs):\n",
    "        base_model.train()  # Set the model to training mode\n",
    "        for curr_batch in train_dataloader:\n",
    "            \n",
    "            if iteration > stop_criterion:\n",
    "                break\n",
    "            \n",
    "            input_ids = curr_batch['input_ids'].to(device)\n",
    "            attention_mask = curr_batch['attention_mask'].to(device)\n",
    "            targets = curr_batch['multi_label'].to(device)\n",
    "\n",
    "\n",
    "            outputs = base_model(input_ids,attention_mask)\n",
    "            loss = loss_function(outputs.to(device), targets)\n",
    "            \n",
    "            if iteration % acc_step == 0:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            #print (iteration)\n",
    "            running_loss.append(loss.item())\n",
    "            if len(running_loss) > 20:\n",
    "                running_loss.pop(0)\n",
    "            #print (f\"Epoch : {epoch} ,Iteration : {iteration}, training loss: {loss:.4f} , running loss:{sum(running_loss)/len(running_loss)}\")            \n",
    "            print (f\"Epoch : {epoch} ,Iteration : {iteration}, training loss: {loss:.4f} , running loss:{sum(running_loss)/len(running_loss)}\",find_metrics(targets,outputs))\n",
    "            \n",
    "            # freeing up excess memory\n",
    "            del loss, outputs\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            # Validation and model saving\n",
    "            if iteration % valid_interval == 0:\n",
    "                base_model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    total_loss = []\n",
    "                    f1_micro = []\n",
    "                    f1_macro = []\n",
    "                    f1_avg = []\n",
    "                    for val_batch in val_dataloader:\n",
    "                        val_input_ids = val_batch['input_ids'].to(device)\n",
    "                        val_attention_mask = val_batch['attention_mask'].to(device)\n",
    "                        val_targets = val_batch['multi_label'].to(device)\n",
    "\n",
    "\n",
    "                        outputs = base_model(val_input_ids,val_attention_mask)\n",
    "                        loss = loss_function(outputs.to(device), val_targets)                        \n",
    "                        \n",
    "                        total_loss.append(loss.item())\n",
    "                        val_out = find_metrics(val_targets,outputs)\n",
    "                        f1_micro.append(val_out[0])\n",
    "                        f1_macro.append(val_out[1])\n",
    "                        f1_avg.append(val_out[2])\n",
    "                        \n",
    "                        # emptying memory\n",
    "                        del val_out, loss, outputs\n",
    "                        gc.collect()\n",
    "                        torch.cuda.empty_cache()\n",
    "                        \n",
    "                    avg_acc = sum(f1_avg)/len(f1_avg)\n",
    "                    avg_f1mic = sum(f1_micro)/len(f1_micro)\n",
    "                    avg_f1mac = sum(f1_macro)/len(f1_macro)\n",
    "                    avg_loss = sum(total_loss)/len(total_loss)\n",
    "                    print (f\"Validation loss : {sum(total_loss)/len(total_loss)} \", ' ,acc : ',avg_acc,\" ,f1-micro : \",avg_f1mic,\" ,f1-macro : \",avg_f1mac)\n",
    "                    torch.save(base_model.state_dict(),f\"model_trained/model_w_{iteration}.pth\")\n",
    "                    #wandb.log({\"Validation Loss\": sum(total_loss)/len(total_loss)})\n",
    "                    del total_loss, f1_micro, f1_macro, f1_avg\n",
    "\n",
    "                base_model.train()  # Set the model back to training mode\n",
    "            \n",
    "            iteration += 1\n",
    "    return base_model, train_dataloader, optimizer, loss_function\n",
    "\n",
    "base_model, train_dataloader_w, optimizer, loss_function = train_w(base_model,train_dataloader_w ,optimizer,loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb13bce",
   "metadata": {},
   "source": [
    "### Computing metrics from the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7323d9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpaueb/legal-bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to test the whole dataset\n",
      "(0.8909541511771994, 0.9386282935822179, 0.8948350964530181, 0.8909541511771994, [(0.4790555978674791, 0.07692307692307693, 0.07894736842105263), (0.42809364548494977, 0.0, 0.0), (0.4318936877076412, 0.0, 0.0), (0.4207920792079208, 0.0, 0.0), (0.4359673024523161, 0.0, 0.0), (0.4320388349514563, 0.0, 0.0), (0.43529411764705883, 0.0, 0.0), (0.4375, 0.0, 0.0), (1.0, 1.0, 1.0)])\n"
     ]
    }
   ],
   "source": [
    "# compute metrics for normal dataset\n",
    "# computer metrics for the entire dataset\n",
    "def compute_f1_score(true_labels, predicted_labels):\n",
    "    num_labels = true_labels.shape[1]\n",
    "    f1_scores = []\n",
    "\n",
    "    for label_idx in range(num_labels):\n",
    "        true_positives = np.sum(np.logical_and(true_labels[:, label_idx], predicted_labels[:, label_idx]))\n",
    "        false_positives = np.sum(np.logical_and(np.logical_not(true_labels[:, label_idx]), predicted_labels[:, label_idx]))\n",
    "        false_negatives = np.sum(np.logical_and(true_labels[:, label_idx], np.logical_not(predicted_labels[:, label_idx])))\n",
    "\n",
    "        precision = true_positives / (true_positives + false_positives + 1e-16)\n",
    "        recall = true_positives / (true_positives + false_negatives + 1e-16)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall + 1e-16)\n",
    "\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    macro_f1_score = np.mean(f1_scores)\n",
    "\n",
    "    return macro_f1_score\n",
    "\n",
    "def gpt_imp(predicted_labels,true_labels):\n",
    "    # Calculate true positives, false positives, and false negatives\n",
    "    true_positives = torch.logical_and(predicted_labels, true_labels).sum().item()\n",
    "    false_positives = (predicted_labels.logical_not() & true_labels).sum().item()\n",
    "    false_negatives = (predicted_labels & true_labels.logical_not()).sum().item()\n",
    "\n",
    "    # Calculate precision, recall, and micro F1 score\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "    micro_f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return micro_f1_score\n",
    "    \n",
    "def find_metrics1(targets,prediction):\n",
    "    final_pred = ((torch.sigmoid(prediction) >= 0.5) * 1.0)\n",
    "    #final_pred = prediction\n",
    "    \n",
    "    append_out = torch.cat((final_pred,((torch.sum(final_pred,dim=1) < 1.0)  * 1.0).unsqueeze(1)),dim=1)\n",
    "    append_tar = torch.cat((targets,((torch.sum(targets,dim=1) < 1.0)  * 1.0).unsqueeze(1)),dim=1)\n",
    "\n",
    "    np_tar = append_tar.cpu().detach().numpy()\n",
    "    np_pred = append_out.cpu().detach().numpy()\n",
    "    \n",
    "    avg_f1_mic = f1_score(np_tar, np_pred, average='micro',zero_division=0)\n",
    "    avg_f1_mac = f1_score(np_tar.flatten(), np_pred.flatten(), average='macro',zero_division=0)\n",
    "    avg_acc = accuracy_score(np_tar, np_pred)\n",
    "    waise_hi = gpt_imp(append_tar.to(torch.int64),append_out.to(torch.int64))\n",
    "    waise_hi3 = per_label(np_tar,np_pred)\n",
    "    del np_tar\n",
    "    del np_pred\n",
    "    del final_pred\n",
    "    \n",
    "    return avg_f1_mic, avg_f1_mac, avg_acc, waise_hi, waise_hi3\n",
    "\n",
    "def compute_metrics(targets,prediction):\n",
    "    # Fix gold labels\n",
    "    y_true = np.zeros((targets.shape[0], p.label_ids.shape[1] + 1), dtype=np.int32)\n",
    "    y_true[:, :-1] = p.label_ids\n",
    "    y_true[:, -1] = (np.sum(p.label_ids, axis=1) == 0).astype('int32')\n",
    "    # Fix predictions\n",
    "    logits = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "    preds = (expit(logits) > 0.5).astype('int32')\n",
    "    y_pred = np.zeros((p.label_ids.shape[0], p.label_ids.shape[1] + 1), dtype=np.int32)\n",
    "    y_pred[:, :-1] = preds\n",
    "    y_pred[:, -1] = (np.sum(preds, axis=1) == 0).astype('int32')\n",
    "    # Compute scores\n",
    "    macro_f1 = f1_score(y_true=y_true, y_pred=y_pred, average='macro', zero_division=0)\n",
    "    micro_f1 = f1_score(y_true=y_true, y_pred=y_pred, average='micro', zero_division=0)\n",
    "    return {'macro-f1': macro_f1, 'micro-f1': micro_f1}\n",
    "\n",
    "\n",
    "def per_label(targets,prediction):\n",
    "    \n",
    "    output_per_lab = []\n",
    "    for i in range(0,9):\n",
    "        samples = targets[:, i] == 1\n",
    "        per_lab_tar = targets[samples] \n",
    "        per_lab_out = prediction[samples]\n",
    "        avg_f1_mic = f1_score(per_lab_tar, per_lab_out, average='micro',zero_division=0)\n",
    "        avg_f1_mac = f1_score(per_lab_tar.flatten(), per_lab_out.flatten(), average='macro',zero_division=0)\n",
    "        avg_acc = accuracy_score(per_lab_tar, per_lab_out)\n",
    "        \n",
    "        output_per_lab.append((avg_f1_mac,avg_f1_mic,avg_acc))\n",
    "    return output_per_lab\n",
    "        \n",
    "def test_whole_data(test_data):\n",
    "    curr_model = BERTClassifier(num_classes)\n",
    "    curr_model.load_state_dict(torch.load(\"/home/anas/Desktop/code/legal_tech_GR/baseline/model_trained/model_0.pth\"))\n",
    "    curr_model.eval()\n",
    "    print (\"Starting to test the whole dataset\")\n",
    "    \n",
    "    \n",
    "    full_metric_out = []\n",
    "    full_metric_tar = []\n",
    "    curr_model.to(device)\n",
    "    iteri = 0\n",
    "    for curr_batch in test_data:\n",
    "        input_ids = curr_batch['input_ids'].to(device)\n",
    "        attention_mask = curr_batch['attention_mask'].to(device)\n",
    "        targets = curr_batch['multi_label'].to(device)\n",
    "        \n",
    "        outputs = curr_model(input_ids,attention_mask)\n",
    "        iteri+=1\n",
    "        if full_metric_out == []:\n",
    "            full_metric_out = outputs.detach().clone()\n",
    "            full_metric_tar = targets.detach().clone()\n",
    "        else:\n",
    "            full_metric_out = torch.cat((full_metric_out,outputs.detach()),dim=0)\n",
    "            full_metric_tar = torch.cat((full_metric_tar,targets.detach()),dim=0)\n",
    "        del outputs,targets,input_ids\n",
    "    \n",
    "    #full_metric_out = (torch.sigmoid(full_metric_out) >= 0.5) * 1.0\n",
    "        \n",
    "    print (find_metrics1(full_metric_tar, full_metric_out))\n",
    "\n",
    "    \n",
    "test_custom = CustomDataset(test_dataset, num_classes,tokenizer)\n",
    "test_dataloader = DataLoader(test_custom, batch_size=batch_size, shuffle=True)\n",
    "test_whole_data(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26b2ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
