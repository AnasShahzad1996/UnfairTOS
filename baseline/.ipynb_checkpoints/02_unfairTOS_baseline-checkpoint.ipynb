{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "084bdc00",
   "metadata": {},
   "source": [
    "## Unfair TOS\n",
    "\n",
    "#### The previous jupyter_notebook contains visualizations for the data. Most of the problematic clauses have many interesting trigrams that we can use in our machine learning or deep learning models. \n",
    "\n",
    "\n",
    "### Baseline experiment\n",
    "1. Simplest model(chery picked example and full dataset)\n",
    "2. Overfit on one cherry picked example\n",
    "3. Write model and training loop\n",
    "4. Run for a larger number of epochs\n",
    "5. Compute metrics\n",
    "6. Try a meta-learning example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f2759f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------# Import libraries and datasets #------#\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import datasets as dts\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "%matplotlib inline\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cc6d374",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset lex_glue (/home/anas/.cache/huggingface/datasets/lex_glue/unfair_tos/1.0.0/8a66420941bf6e77a7ddd4da4d3bfb7ba88ef48c1d55302a568ac650a095ca3a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "102dea1e87214b5889935b2ee01780fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dts.load_dataset('lex_glue','unfair_tos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10780b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.DataFrame.from_dict(dataset[\"train\"])\n",
    "val_dataset = pd.DataFrame.from_dict(dataset[\"validation\"])\n",
    "test_dataset = pd.DataFrame.from_dict(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2eb35b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# function to remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    no_stopword_text = [w for w in text.split() if not w in stop_words]\n",
    "    return ' '.join(no_stopword_text)\n",
    "\n",
    "#Clean Text\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"[^a-zA-Z]\",\" \",text) \n",
    "    text = ' '.join(text.split()) \n",
    "    return text\n",
    "\n",
    "#stemming\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "def stemming(sentence):\n",
    "    stemSentence = \"\"\n",
    "    for word in sentence.split():\n",
    "        stem = stemmer.stem(word)\n",
    "        stemSentence += stem\n",
    "        stemSentence += \" \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a9f4d3",
   "metadata": {},
   "source": [
    "### Using a simple logistic regression\n",
    "In the below example we use a simple logistic regression model with \n",
    "1. Binary relevance where we have four separate classifiers but their is no label correlation. The performance is obviously very bad.\n",
    "2. Classifier chain. The performance for this is even worse\n",
    "3. Binary relevance with simple undersampling\n",
    "4. Binary relevance with tomek undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db30941a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.910392034847542\n",
      "micro-F1 score is  0.2972972972972973\n",
      "macro-F1 score is  0.2394898528151031\n",
      "Hamming Loss is  0.012134411947728687\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                ('clf', BinaryRelevance(LogisticRegression(solver='sag'))),\n",
    "            ])\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(train_dataset['labels'])\n",
    "y_transformed = mlb.transform(train_dataset['labels'])\n",
    "\n",
    "pipeline.fit(train_dataset['text'], y_transformed)\n",
    "\n",
    "\n",
    "predictions = pipeline.predict(test_dataset[\"text\"])\n",
    "\n",
    "\n",
    "print('Accuracy = ', accuracy_score(mlb.transform(test_dataset[\"labels\"]),predictions))\n",
    "print('micro-F1 score is ',f1_score(mlb.transform(test_dataset[\"labels\"]), predictions, average=\"micro\"))\n",
    "print('macro-F1 score is ',f1_score(mlb.transform(test_dataset[\"labels\"]), predictions, average=\"macro\"))\n",
    "print('Hamming Loss is ', hamming_loss(mlb.transform(test_dataset[\"labels\"]), predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33b43437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.9079029247044181\n",
      "micro-F1 score is  0.2780269058295964\n",
      "macro-F1 score is  0.1967032967032967\n",
      "Hamming Loss is  0.012523335407591787\n"
     ]
    }
   ],
   "source": [
    "pipeline2 = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                ('clf', ClassifierChain(LogisticRegression(solver='sag'))),\n",
    "            ])\n",
    "\n",
    "pipeline2.fit(train_dataset['text'], y_transformed)\n",
    "\n",
    "\n",
    "predictions = pipeline2.predict(test_dataset[\"text\"])\n",
    "\n",
    "\n",
    "print('Accuracy = ', accuracy_score(mlb.transform(test_dataset[\"labels\"]),predictions))\n",
    "print('micro-F1 score is ',f1_score(mlb.transform(test_dataset[\"labels\"]), predictions, average=\"micro\"))\n",
    "print('macro-F1 score is ',f1_score(mlb.transform(test_dataset[\"labels\"]), predictions, average=\"macro\"))\n",
    "print('Hamming Loss is ', hamming_loss(mlb.transform(test_dataset[\"labels\"]), predictions))\n",
    "\n",
    "# THe accuray of the classifier chain is even less. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd21e4e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LabelPowerset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11685/2104900043.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m pipeline3 = Pipeline([\n\u001b[1;32m      2\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0;34m'tfidf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLabelPowerset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m             ])\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LabelPowerset' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10a3fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
